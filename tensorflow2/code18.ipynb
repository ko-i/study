{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5nWGtnEnL12LgMmQcWV42"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRdI0eMFWRw2"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4hXjlJsZhW_"
      },
      "source": [
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2uFSHnoaEEa"
      },
      "source": [
        "dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url, True, cache_dir='.', cache_subdir='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM0lXu1aadiQ"
      },
      "source": [
        "os.listdir(os.path.dirname(dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz8NBdx6aRDV"
      },
      "source": [
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp7Twf4zaopN"
      },
      "source": [
        "os.listdir(dataset_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnAz5Uk7aspJ"
      },
      "source": [
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9TsyvM7a98i"
      },
      "source": [
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yvxh-kgbLZT"
      },
      "source": [
        "os.listdir(train_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIEms7SIbN0E"
      },
      "source": [
        "batch_size = 1024\n",
        "seed = 123\n",
        "\n",
        "train_ds = tf.keras.preprocessing.text_dataset_from_directory('aclImdb/train', batch_size=batch_size, validation_split=0.2, subset='training', seed=seed)\n",
        "val_ds = tf.keras.preprocessing.text_dataset_from_directory('aclImdb/train', batch_size=batch_size, validation_split=0.2, subset='validation', seed=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyPKIe25dN4p"
      },
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "    for i in range(5):\n",
        "        print(label_batch[i].numpy(), text_batch.numpy()[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cO1qR2rdmaS"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9unS6GE_ecmg"
      },
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(1000, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjNFmJcEevio"
      },
      "source": [
        "result = embedding_layer(tf.constant([1, 2, 3]))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tkfmaznft71"
      },
      "source": [
        "result = embedding_layer(tf.constant([1, 2, 3, 4, 5]))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JLqo2YVfxL1"
      },
      "source": [
        "result = embedding_layer(tf.constant([[1, 2, 3], [4, 5, 6]]))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxn1fieFgMYJ"
      },
      "source": [
        "def custom_standardization(input_data):\n",
        "    lower_case = tf.strings.lower(input_data)\n",
        "    stripped_html = tf.strings.regex_replace(lower_case, '<br />', ' ')\n",
        "    return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "New1oDPTix9b"
      },
      "source": [
        "vocab_size = 10000\n",
        "sequence_length = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4wCCrRKi5Kl"
      },
      "source": [
        "vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=vocab_size, standardize=custom_standardization, output_sequence_length=sequence_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi4okESzkSZy"
      },
      "source": [
        "test_ds = train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6WHaG2Vk1xn"
      },
      "source": [
        "embedding_dim = 16\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    vectorize_layer,\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, name='embedding'),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(16, 'relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdXYZpvio5R2"
      },
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF8WyiYwpIeW"
      },
      "source": [
        "model.compile('adam', loss=tf.keras.losses.BinaryCrossentropy(True), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuAAYgYGpUFU"
      },
      "source": [
        "model.fit(train_ds, validation_data=val_ds, epochs=15, callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0uGtaiVphrn"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkLd9_P2p0us"
      },
      "source": [
        "!load_ext tensorboard\n",
        "!tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfrkcuy1p_J-"
      },
      "source": [
        "weights = model.get_layer('embedding').get_weights()[0]\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUwd4UcGrDGI"
      },
      "source": [
        "vocab = vectorize_layer.get_vocabulary()\n",
        "# vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANUefRsirK-3"
      },
      "source": [
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(vocab):\n",
        "    if index == 0:\n",
        "        continue\n",
        "    \n",
        "    vec = weights[index]\n",
        "    out_v.write('\\t'.join([str(x) for x in vec]) + '\\n')\n",
        "    out_m.write(word + '\\n')\n",
        "\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOoz6DahsS7k"
      },
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('vectors.tsv')\n",
        "    foles.download('metadata.tsv')\n",
        "except Exception:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXEy-G6Ssl6i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}