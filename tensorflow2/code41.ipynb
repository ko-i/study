{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLsHdMJQ5sp3MK6IZetgu4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNZo0VjC1K_b"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_dRYzwW1TvF"
      },
      "source": [
        "inputs = keras.Input((784,), name='digits')\n",
        "x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
        "x = layers.Dense(64, activation='relu', name='dense_2')(x)\n",
        "outputs = layers.Dense(10, activation='softmax', name='predictions')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unk4THfo3GsM"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
        "\n",
        "y_train = y_train.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BCxGd_z33FR"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOFP7DRZ4S4I"
      },
      "source": [
        "print('Training')\n",
        "history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fti0OPc24i9Y"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAb_rTxe4oFO"
      },
      "source": [
        "print('Evaluate on test set')\n",
        "loss, acc = model.evaluate(x_test, y_test, batch_size=128)\n",
        "print('loss, acc = ', loss, acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHjANIbb6Meq"
      },
      "source": [
        "predictions = model.predict(x_test[:3])\n",
        "print(tf.argmax(predictions, -1))\n",
        "print(y_test[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEVUEAuv62p_"
      },
      "source": [
        "def get_uncompiled_model():\n",
        "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "def get_compiled_model():\n",
        "    model = get_uncompiled_model()\n",
        "    model.compile(\n",
        "        optimizer=\"rmsprop\",\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"sparse_categorical_accuracy\"],\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG7d5rVf9BcN"
      },
      "source": [
        "def custom_mean_square_error(y_true, y_pred):\n",
        "    return tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "model = get_uncompiled_model()\n",
        "model.compile(optimizer='adam', loss=custom_mean_square_error)\n",
        "\n",
        "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
        "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtluaXVN-DnN"
      },
      "source": [
        "class CustomMSE(keras.losses.Loss):\n",
        "    def __init__(self, regularization_factor=0.1, name='custom_mse'):\n",
        "        super().__init__(name=name)\n",
        "        self.regularization_factor=regularization_factor\n",
        "    \n",
        "    def call(self, y_true, y_pred):\n",
        "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
        "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))\n",
        "        return mse - reg * self.regularization_factor\n",
        "\n",
        "model = get_uncompiled_model()\n",
        "model.compile(optimizer=keras.optimizers.Adam(), loss=CustomMSE())\n",
        "\n",
        "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
        "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYkA5kZQ_BXq"
      },
      "source": [
        "class CategoricalTruePositive(keras.metrics.Metric):\n",
        "    def __init__(self, name='categorical_true_positives', **kwargs):\n",
        "        super(CategoricalTruePositive, self).__init__(name=name, **kwargs)\n",
        "        self.true_positives = self.add_weight(name='ctp', initializer='zeros')\n",
        "    \n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
        "        values = tf.cast(y_true, 'int32') == tf.cast(y_pred, 'int32')\n",
        "        values = tf.cast(values, 'float32')\n",
        "        \n",
        "        if sample_weight is not None:\n",
        "            sample_weight = tf.cast(sample_weight, 'float32')\n",
        "            values = tf.multiply(values, sample_weight)\n",
        "        \n",
        "        self.true_positives.assign_add(tf.reduce_sum(values))\n",
        "    \n",
        "    def result(self):\n",
        "        return self.true_positives\n",
        "    \n",
        "    def reset_states(self):\n",
        "        self.true_positives.assign(0.0)\n",
        "\n",
        "model = get_uncompiled_model()\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-3), loss=keras.losses.SparseCategoricalCrossentropy(), metrics=[CategoricalTruePositive()])\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m-szvx0Jh18"
      },
      "source": [
        "class ActivityRegularizationLayer(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        self.add_loss(tf.reduce_sum(inputs * 0.1))\n",
        "        return inputs\n",
        "\n",
        "inputs = keras.Input(shape=(784,), name='digits')\n",
        "x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
        "x = ActivityRegularizationLayer()(x)\n",
        "\n",
        "x = layers.Dense(64, activation='relu', name='dense_2')(x)\n",
        "outputs = layers.Dense(10, name='predictions')(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-3), loss=keras.losses.SparseCategoricalCrossentropy(True))\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFeO8f8gXV0D"
      },
      "source": [
        "class MetricLoggingLayer(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        self.add_metric(keras.backend.std(inputs), name='std_of_activation', aggregation='mean')\n",
        "        return inputs\n",
        "\n",
        "inputs = keras.Input(shape=(784, ), name='digits')\n",
        "x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
        "x = MetricLoggingLayer()(x)\n",
        "x = layers.Dense(64, activation='relu', name='dense_2')(x)\n",
        "outputs = layers.Dense(10, name='predictions')(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-3), loss=keras.losses.SparseCategoricalCrossentropy(True))\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKqae9mTZFON"
      },
      "source": [
        "inputs = keras.Input(shape=(784,), name='digits')\n",
        "x1 = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
        "x2 = layers.Dense(64, activation='relu', name='dense_2')(x1)\n",
        "outputs = layers.Dense(10, name='predictions')(x2)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.add_loss(tf.reduce_sum(x1) * 0.1)\n",
        "model.add_metric(keras.backend.std(x1), name=\"std_of_activation\", aggregation=\"mean\")\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-3), loss=keras.losses.SparseCategoricalCrossentropy(True))\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90_MlZC3fH_w"
      },
      "source": [
        "class LogisticEndpoint(keras.layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super(LogisticEndpoint, self).__init__(name=name)\n",
        "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
        "    \n",
        "    def call(self, targets, logits, sample_weights=None):\n",
        "        loss = self.loss_fn(targets, logits, sample_weights)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
        "        self.add_metric(acc, name='accuracy')\n",
        "\n",
        "        return tf.nn.softmax(logits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n5T7g_mkZw4"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "inputs = keras.Input(shape=(3,), name='inputs')\n",
        "targets = keras.Input(shape=(10,), name='targets')\n",
        "logits = layers.Dense(10)(inputs)\n",
        "predictions = LogisticEndpoint(name='predictions')(logits, targets)\n",
        "\n",
        "model = keras.Model([inputs, targets], predictions)\n",
        "model.compile('adam')\n",
        "\n",
        "data = {\n",
        "    'inputs': np.random.random((3,3)),\n",
        "    'targets': np.random.random((3,10)),\n",
        "}\n",
        "\n",
        "model.fit(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89ir5-lBlk7_"
      },
      "source": [
        "model = get_compiled_model()\n",
        "model.fit(x_train, y_train, batch_size=64, validation_split=0.2, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHDVeTLBm_Gq"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = test_dataset.batch(64)\n",
        "\n",
        "model.fit(train_dataset, epochs=3)\n",
        "\n",
        "print('Evaluate:')\n",
        "result = model.evaluate(test_dataset)\n",
        "dict(zip(model.metrics_names, result))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMGDsXRMqKni"
      },
      "source": [
        "model = get_compiled_model()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "model.fit(train_dataset, epochs=3, steps_per_epoch=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDFVCxrkrt0d"
      },
      "source": [
        "model = get_compiled_model()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(64)\n",
        "\n",
        "model.fit(train_dataset, epochs=1, validation_data=val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0enYdSD0s3wQ"
      },
      "source": [
        "model = get_compiled_model()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(64)\n",
        "\n",
        "model.fit(train_dataset, epochs=1, validation_data=val_dataset, validation_steps=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhNG6eBxu3fw"
      },
      "source": [
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "\n",
        "class CIFAR10Sequence(keras.utils.Sequence):\n",
        "    def __init__(self, filenames, labels, batch_size):\n",
        "        self.filenames, self.labels = filenames, labels\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.filenames[idx * self.batch_size: (idx+1) * self.batch_size]\n",
        "        batch_y = self.labels[idx * self.batch_size: (idx+1) * self.batch_size]\n",
        "\n",
        "        return np.array([resize(imread(filename), (200, 200)) for filename in batch_x]), np.array(batch_y)\n",
        "\n",
        "# sequence = CIFAR10Sequence(filenames, labels, batch_size)\n",
        "# model.fit(sequence, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrWFQ73P02mR"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class_weight = {\n",
        "    0: 1.0,\n",
        "    1: 1.0,\n",
        "    2: 1.0,\n",
        "    3: 1.0,\n",
        "    4: 1.0,\n",
        "    # Set weight \"2\" for class \"5\",\n",
        "    # making this class 2x more important\n",
        "    5: 2.0,\n",
        "    6: 1.0,\n",
        "    7: 1.0,\n",
        "    8: 1.0,\n",
        "    9: 1.0,\n",
        "}\n",
        "\n",
        "print(\"Fit with class weight\")\n",
        "model = get_compiled_model()\n",
        "model.fit(x_train, y_train, class_weight=class_weight, batch_size=64, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZhBm1iu2Iof"
      },
      "source": [
        "sample_weight = np.ones(shape=(len(y_train), ))\n",
        "sample_weight[y_train == 5] = 2.0\n",
        "\n",
        "model = get_compiled_model()\n",
        "model.fit(x_train, y_train, sample_weight=sample_weight, batch_size=64, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjZKvmlw3ZoG"
      },
      "source": [
        "sample_weights = np.ones(shape=(len(y_train), ))\n",
        "sample_weight[y_train == 5] = 2.0\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, sample_weight))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "model = get_compiled_model()\n",
        "model.fit(train_dataset, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5PucyAe5SR0"
      },
      "source": [
        "image_input = keras.Input(shape=(32, 32, 3), name='img_input')\n",
        "timeseries_input = keras.Input(shape=(None, 10), name='ts_input')\n",
        "\n",
        "x1 = layers.Conv2D(3, 3)(image_input)\n",
        "x1 = layers.GlobalMaxPooling2D()(x1)\n",
        "\n",
        "x2 = layers.Conv1D(3, 3)(timeseries_input)\n",
        "x2 = layers.GlobalMaxPooling1D()(x2)\n",
        "\n",
        "x = layers.concatenate([x1, x2])\n",
        "\n",
        "score_output = layers.Dense(1, name='score_output')(x)\n",
        "class_output = layers.Dense(5, name='class_output')(x)\n",
        "\n",
        "model = keras.Model(inputs=[image_input, timeseries_input], outputs=[score_output, class_output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRaJXodt7GfB"
      },
      "source": [
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBsJKLuX7L0f"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-3), loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XJ2U8qe9D54"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = keras.optimizers.RMSprop(1e-3),\n",
        "    loss = [\n",
        "        keras.losses.MeanSquaredError(),\n",
        "        keras.losses.CategoricalCrossentropy(),\n",
        "    ],\n",
        "    metrics = [\n",
        "        [\n",
        "            keras.metrics.MeanAbsolutePercentageError(),\n",
        "            keras.metrics.MeanAbsoluteError()\n",
        "        ],\n",
        "        [\n",
        "            keras.metrics.CategoricalAccuracy()\n",
        "        ]\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxyahtIV9_rQ"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = keras.optimizers.RMSprop(1e-3),\n",
        "    loss = {\n",
        "        'score_output': keras.losses.MeanSquaredError(),\n",
        "        'class_output': keras.losses.CategoricalCrossentropy(),\n",
        "    },\n",
        "    metrics = {\n",
        "        'score_output': [\n",
        "            keras.metrics.MeanAbsolutePercentageError(),\n",
        "            keras.metrics.MeanAbsoluteError()\n",
        "        ],\n",
        "        'class_output': [\n",
        "            keras.metrics.CategoricalAccuracy()\n",
        "        ]\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLu1aUlC-Sos"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = keras.optimizers.RMSprop(1e-3),\n",
        "    loss = {\n",
        "        'score_output': keras.losses.MeanSquaredError(),\n",
        "        'class_output': keras.losses.CategoricalCrossentropy(),\n",
        "    },\n",
        "    metrics = {\n",
        "        'score_output': [\n",
        "            keras.metrics.MeanAbsolutePercentageError(),\n",
        "            keras.metrics.MeanAbsoluteError()\n",
        "        ],\n",
        "        'class_output': [\n",
        "            keras.metrics.CategoricalAccuracy()\n",
        "        ]\n",
        "    },\n",
        "    loss_weights = {'score_output': 2.0, 'class_output': 1.0}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB2bOBLm--qb"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss=[None, keras.losses.CategoricalCrossentropy()]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss={'class_output': keras.losses.CategoricalCrossentropy()}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUyagjorC7t0"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
        ")\n",
        "\n",
        "img_data = np.random.random_sample(size=(100, 32, 32, 3))\n",
        "ts_data = np.random.random_sample(size=(100, 20, 10))\n",
        "\n",
        "score_targets = np.random.random_sample(size=(100, 1))\n",
        "class_targets = np.random.random_sample(size=(100, 5))\n",
        "\n",
        "model.fit([img_data, ts_data], [score_targets, class_targets], batch_size=64, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h3D7kZ1EdYf"
      },
      "source": [
        "model.fit(\n",
        "    {\n",
        "        'img_input': img_data,\n",
        "        'ts_input': ts_data,\n",
        "    },\n",
        "    {\n",
        "        'score_output': score_targets,\n",
        "        'class_output': class_targets,\n",
        "    },\n",
        "    batch_size=64,\n",
        "    epochs=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEc2bDkMExjr"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "        {'img_input': img_data, 'ts_input': ts_data},\n",
        "        {'score_output': score_targets, 'class_output': class_targets}\n",
        "    )\n",
        ")\n",
        "\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "model.fit(train_dataset, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTrlhev6F_IQ"
      },
      "source": [
        "model = get_compiled_model()\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-2, patience=2, verbose=1)]\n",
        "\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64, callbacks=callbacks, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "986h_O9iHFBC"
      },
      "source": [
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs):\n",
        "        self.per_batch_losses =[]\n",
        "    \n",
        "    def on_batch_end(self, batch, logs):\n",
        "        self.per_batch_losses.append(logs.get('loss'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWpSVv1_H2zS"
      },
      "source": [
        "model = get_compiled_model()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(filepath='mymodel_{epoch}', save_best_only=True, monitor='val_loss', verbose=1)\n",
        "]\n",
        "\n",
        "model.fit(x_train, y_train, epochs=2, batch_size=64, callbacks=callbacks, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I7sJniXC4j9"
      },
      "source": [
        "import os\n",
        "\n",
        "checkpoint_dir = './ckpt'\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "def make_or_restore_model():\n",
        "    checkpoints = [checkpoint_dir + '/' + name for name in os.listdir(checkpoint_dir)]\n",
        "\n",
        "    if checkpoints:\n",
        "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
        "        print('Restoring from', latest_checkpoint)\n",
        "        return keras.modes.load_model(latest_checkpoint)\n",
        "    \n",
        "    print('Create a new model')\n",
        "    return get_compiled_model()\n",
        "\n",
        "model = make_or_restore_model()\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir + '/ckpt-loss={loss:.2f}', save_freq=100)\n",
        "]\n",
        "\n",
        "model.fit(x_train, y_train, epochs=1, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHovcraYGd0C"
      },
      "source": [
        "initial_learning_rate = 0.1\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True)\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CixMifNqHqy6"
      },
      "source": [
        "keras.callbacks.TensorBoard(\n",
        "    log_dir='/full_path_to_your_logs',\n",
        "    histogram_freq=0,\n",
        "    embeddings_freq=0,\n",
        "    update_freq='epoch'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}