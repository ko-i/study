{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLxZaunidKqDDa2+Xcdo9M"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfiQQmfn010P"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import cProfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBcfqhQJ1Fq5"
      },
      "source": [
        "tf.executing_eagerly()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8pvb8C61Op-"
      },
      "source": [
        "x = [[2.]]\n",
        "m = tf.matmul(x, x)\n",
        "print('hello, {}'.format(m))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGS-Akc91bxq"
      },
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htj9Xv7r8KRA"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0uoYSBC8LOj"
      },
      "source": [
        "a.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94dKasF38Rss"
      },
      "source": [
        "b = tf.add(a, 1)\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5l1CIv78W2b"
      },
      "source": [
        "print(a * b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyrxYTcc8cua"
      },
      "source": [
        "print(tf.matmul(a, b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9coDQ-ZQ8eUF"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkVjqXKv8nXb"
      },
      "source": [
        "print(np.multiply(a, b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2Nn_Fkl8wMu"
      },
      "source": [
        "def fizzbuzz(max_num):\n",
        "    counter = tf.constant(0)\n",
        "    max_num = tf.convert_to_tensor(max_num)\n",
        "    for num in range(1, max_num.numpy() + 1):\n",
        "        if int(num % 3) == 0 and int(num % 5) == 0:\n",
        "            print('FizzBuzz')\n",
        "        elif int(num % 3) == 0:\n",
        "            print('Fizz')\n",
        "        elif int(num % 5) == 0:\n",
        "            print('Buzz')\n",
        "        else:\n",
        "            print(num)\n",
        "        counter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGkKQHKR-c-6"
      },
      "source": [
        "fizzbuzz(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_khGwIJ-e7m"
      },
      "source": [
        "w = tf.Variable([[1.0]])\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    loss = w * w\n",
        "\n",
        "grad = tape.gradient(loss, w)\n",
        "print(grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciS2xphsyklf"
      },
      "source": [
        "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((tf.cast(mnist_images[..., tf.newaxis] / 255, tf.float32), tf.cast(mnist_labels, tf.int64)))\n",
        "dataset = dataset.shuffle(1000).batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIoIrS8v0IjN"
      },
      "source": [
        "mnist_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, [3, 3], activation='relu', input_shape=(None, None, 1)),\n",
        "    tf.keras.layers.Conv2D(16, [3, 3], activation='relu'),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-uq3z5Y0_4e"
      },
      "source": [
        "for images, labels in dataset.take(1):\n",
        "    logit = mnist_model(images)[0].numpy()\n",
        "    print(\"Logit: \", logit)\n",
        "    print(\"Prediction: {}, Label: {}\".format(tf.argmax(logit), labels[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TpGzdqK1K4W"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(True)\n",
        "\n",
        "loss_history = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZQXbthd2vSz"
      },
      "source": [
        "# 每一个训练步骤，传入一个batch的样本和标签\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # 使用当前模型计算结果\n",
        "        logits = mnist_model(images, training=True)\n",
        "        # 检查结果的形状（可不要）\n",
        "        tf.debugging.assert_equal(logits.shape, (32, 10))\n",
        "        # 计算loss\n",
        "        loss_value = loss_object(labels, logits)\n",
        "    \n",
        "    # 将本次的loss记录下来\n",
        "    loss_history.append(loss_value.numpy().mean())\n",
        "    # 自动计算每个可训练参数的的梯度\n",
        "    grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
        "    # 采用适当的优化器来调整参数\n",
        "    optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fnSnjQx3uF9"
      },
      "source": [
        "def train(epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for (batch, (images, labels)) in enumerate(dataset):\n",
        "            train_step(images, labels)\n",
        "        \n",
        "        print(\"Epoch {} finished.\".format(epoch+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drp-X-054rdY"
      },
      "source": [
        "train(epochs=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp62-wlG5-LA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(28, 4))\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel(\"Batch #\")\n",
        "plt.ylabel(\"Loss[entropy]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG7QtDre4tbO"
      },
      "source": [
        "class Linear(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Linear, self).__init__()\n",
        "        \n",
        "        self.W = tf.Variable(5., name='weight')\n",
        "        self.B = tf.Variable(10., name='bias')\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return self.W * inputs + self.B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHOVw8kTA4zh"
      },
      "source": [
        "NUM_EXAMPLES = 2000\n",
        "training_inputs = tf.random.normal([NUM_EXAMPLES])\n",
        "noise = tf.random.normal([NUM_EXAMPLES])\n",
        "training_outputs = training_inputs * 3 + 2 + noise\n",
        "\n",
        "def loss(model, input, target):\n",
        "    error = model(input) - target\n",
        "    return tf.reduce_mean(tf.square(error))\n",
        "\n",
        "def grad(model, input, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, input, target)\n",
        "    \n",
        "    return tape.gradient(loss_value, [model.W, model.B])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhDOlW8PCNTs"
      },
      "source": [
        "model = Linear()\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "print(\"Initial Loss = {}\".format(loss(model, training_inputs, training_outputs)))\n",
        "\n",
        "steps = 1000\n",
        "for i in range(steps):\n",
        "    grads = grad(model, training_inputs, training_outputs)\n",
        "    optimizer.apply_gradients(zip(grads, [model.W, model.B]))\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(\"Loss at step {}: {}\".format(i, loss(model, training_inputs, training_outputs)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtOfGu87DbXm"
      },
      "source": [
        "print('W: {}, B: {}'.format(model.W.numpy(), model.B.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0fqVyncEO8A"
      },
      "source": [
        "model.save_weights('weights')\n",
        "status = model.load_weights('weights')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilk9gAlsEbEB"
      },
      "source": [
        "x = tf.Variable(10.)\n",
        "checkpoint = tf.train.Checkpoint(x=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHPx4PNtIH07"
      },
      "source": [
        "x.assign(2.)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhKP1G-HIKBA"
      },
      "source": [
        "checkpoint_path = './ckpt/'\n",
        "checkpoint.save(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlGq_Go-IU9E"
      },
      "source": [
        "x.assign(11.)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWuE5WfIIihk"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTUQZ9gqItUq"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, [3,3], activation='relu'),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "checkpoint_path = 'path/to/model_dir'\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    os.makedirs(checkpoint_path)\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_path, 'ckpt')\n",
        "root = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
        "\n",
        "root.save(checkpoint_prefix)\n",
        "root.restore(tf.train.latest_checkpoint(checkpoint_prefix))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9MSuLDeGHNK"
      },
      "source": [
        "m = tf.keras.metrics.Mean('loss')\n",
        "m(0)\n",
        "print(m.result())\n",
        "m(5)\n",
        "print(m.result())\n",
        "m([8, 9])\n",
        "print(m.result())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwfNIfiYHBZB"
      },
      "source": [
        "logdir = './tb/'\n",
        "writer = tf.summary.create_file_writer(logdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AboxCM0jIc7W"
      },
      "source": [
        "steps = 1000\n",
        "with writer.as_default():\n",
        "    for i in range(steps):\n",
        "        step = i + 1\n",
        "        loss = 1 - 0.001 * step\n",
        "        if step % 100 == 0:\n",
        "            tf.summary.scalar('loss', loss, step=step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLHVroBLJrYN"
      },
      "source": [
        "!ls tb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F4EoNIXJuKx"
      },
      "source": [
        "def line_search_step(fn, init_x, rate=1.0):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(init_x)\n",
        "        value = fn(init_x)\n",
        "    \n",
        "    grad = tape(value, init_x)\n",
        "    grad_norm = tf.reduce_sum(grad * grad)\n",
        "    init_value = value\n",
        "\n",
        "    while value > init_value - rate * grad_norm:\n",
        "        x = init_x - rate * grad\n",
        "        value = fn(x)\n",
        "        rate /= 2.0\n",
        "    \n",
        "    return x, value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gParvfuHLrWP"
      },
      "source": [
        "@tf.custom_gradient\n",
        "def clip_gradient_by_norm(x, norm):\n",
        "    y = tf.identity(x)\n",
        "    \n",
        "    def grad_fn(dresult):\n",
        "        return [tf.clip_by_norm(dresult, norm), None]\n",
        "    \n",
        "    return y, grad_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQsPSoDgM3Zv"
      },
      "source": [
        "def log1pexp(x):\n",
        "    return tf.math.log(1 + tf.exp(x))\n",
        "\n",
        "def grad_log1pexp(x):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(x)\n",
        "        value = log1pexp(x)\n",
        "    \n",
        "    return tape.gradient(value, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_mRiZeyOO8Z"
      },
      "source": [
        "grad_log1pexp(tf.constant([0., 0.])).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-fL3nUzOV80"
      },
      "source": [
        "grad_log1pexp(tf.constant([100., 0.])).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv7Bq0rBOqNa"
      },
      "source": [
        "@tf.custom_gradient\n",
        "def log1pexp(x):\n",
        "    e = tf.exp(x)\n",
        "    def grad(dy):\n",
        "        return dy * (1 - 1 / (1 + e))\n",
        "    \n",
        "    return tf.math.log(1 + e), grad\n",
        "\n",
        "def grad_log1pexp(x):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(x)\n",
        "        value = log1pexp(x)\n",
        "    \n",
        "    return tape.gradient(value, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYM4nM7WRSIX"
      },
      "source": [
        "print(grad_log1pexp(tf.constant(100.)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpT-nDgPRYJf"
      },
      "source": [
        "import time\n",
        "\n",
        "def measure(x, steps):\n",
        "    tf.matmul(x, x)\n",
        "    start = time.time()\n",
        "    for i in range(steps):\n",
        "        x = tf.matmul(x, x)\n",
        "    _ = x.numpy()\n",
        "    end = time.time()\n",
        "    return end - start\n",
        "\n",
        "shape = (1000, 1000)\n",
        "steps = 200\n",
        "\n",
        "print(\"Time to multiply a {} matrix by itself {} time\".format(shape, steps))\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "    print(\"CPU: {} secs.\".format(measure(tf.random.normal(shape), steps)))\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    print(\"GPU: {} secs.\".format(measure(tf.random.normal(shape), steps)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NkViTjMUWbl"
      },
      "source": [
        "if tf.config.list_physical_devices(\"GPU\"):\n",
        "    x = tf.random.normal([10, 10])\n",
        "\n",
        "    x_gpu0 = x.gpu()\n",
        "    x_cpu = x.cpu()\n",
        "\n",
        "    _ = tf.matmul(x_gpu0, x_gpu0)\n",
        "    _ = tf.matmul(x_cpu, x_cpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8Tt9oOhV62r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}