{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMdmVDHf4GPySZ57s5xY4RW"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN7Z-N0kwvsZ"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "data = np.array([[0.1, 0.2, 0.3], [0.8, 0.9, 1.0], [1.5, 1.6, 1.7],])\n",
        "layer = preprocessing.Normalization()\n",
        "layer.adapt(data)\n",
        "normalized_data = layer(data)\n",
        "\n",
        "print('Features mean: ', normalized_data.numpy().mean())\n",
        "print('Features std: ', normalized_data.numpy().std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCfjFbp_1aWG"
      },
      "source": [
        "data = [\n",
        "    \"ξεῖν᾽, ἦ τοι μὲν ὄνειροι ἀμήχανοι ἀκριτόμυθοι\",\n",
        "    \"γίγνοντ᾽, οὐδέ τι πάντα τελείεται ἀνθρώποισι.\",\n",
        "    \"δοιαὶ γάρ τε πύλαι ἀμενηνῶν εἰσὶν ὀνείρων:\",\n",
        "    \"αἱ μὲν γὰρ κεράεσσι τετεύχαται, αἱ δ᾽ ἐλέφαντι:\",\n",
        "    \"τῶν οἳ μέν κ᾽ ἔλθωσι διὰ πριστοῦ ἐλέφαντος,\",\n",
        "    \"οἵ ῥ᾽ ἐλεφαίρονται, ἔπε᾽ ἀκράαντα φέροντες:\",\n",
        "    \"οἱ δὲ διὰ ξεστῶν κεράων ἔλθωσι θύραζε,\",\n",
        "    \"οἵ ῥ᾽ ἔτυμα κραίνουσι, βροτῶν ὅτε κέν τις ἴδηται.\",\n",
        "]\n",
        "\n",
        "layer = preprocessing.TextVectorization()\n",
        "layer.adapt(data)\n",
        "vectorized_text = layer(data)\n",
        "print(vectorized_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy3prund13qm"
      },
      "source": [
        "vocab = ['a', 'b', 'c', 'd']\n",
        "data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n",
        "layer = preprocessing.StringLookup(vocabulary=vocab)\n",
        "vectorized_data = layer(data)\n",
        "print(vectorized_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyj1GJF44Gcf"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxVMRAvI6TST"
      },
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "    preprocessing.RandomFlip('horizontal'),\n",
        "    preprocessing.RandomRotation(0.1),\n",
        "    preprocessing.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "classes = 10\n",
        "inputs = keras.Input(input_shape)\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocessing.Rescaling(1.0 / 255)(x)\n",
        "outputs = keras.applications.ResNet50(weights=None, input_shape=input_shape, classes=classes)(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqi_10J67b_5"
      },
      "source": [
        "(x_train, y_train), _ = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.reshape((len(x_train), -1))\n",
        "input_shape = x_train.shape[1:]\n",
        "classes = 10\n",
        "\n",
        "normalizer = preprocessing.Normalization()\n",
        "normalizer.adapt(x_train)\n",
        "\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "x = normalizer(inputs)\n",
        "outputs = keras.layers.Dense(classes, activation='softmax')(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\")\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgi4acDzpFds"
      },
      "source": [
        "data = tf.constant(['a', 'b', 'c', 'b', 'c', 'a'])\n",
        "indexer = preprocessing.StringLookup()\n",
        "indexer.adapt(data)\n",
        "\n",
        "encoder = preprocessing.CategoryEncoding(num_tokens=5, output_mode='binary')\n",
        "encoder.adapt(indexer(data))\n",
        "\n",
        "test_data = tf.constant([\"a\", \"b\", \"c\", \"d\", \"e\", \"\"])\n",
        "encoded_data = encoder(indexer(test_data))\n",
        "print(encoded_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1GAc-2Hsr2e"
      },
      "source": [
        "data = tf.constant([10, 20, 20, 10, 30, 0])\n",
        "\n",
        "indexer = preprocessing.IntegerLookup()\n",
        "indexer.adapt(data)\n",
        "\n",
        "encoder = preprocessing.CategoryEncoding(num_tokens=5, output_mode='binary')\n",
        "encoder.adapt(indexer(data))\n",
        "\n",
        "test_data = tf.constant([10, 10, 20, 50, 60, 0])\n",
        "encoded_data = encoder(indexer(test_data))\n",
        "print(encoded_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkB8kjr0vEWE"
      },
      "source": [
        "data = np.random.randint(0, 100000, size=(10000, 1))\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bShQIKfExMLK"
      },
      "source": [
        "hasher = preprocessing.Hashing(num_bins=64, salt=1337)\n",
        "encoder = preprocessing.CategoryEncoding(num_tokens=64, output_mode='binary')\n",
        "encoded_data = encoder(hasher(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fdB6b5yxoQ3"
      },
      "source": [
        "encoded_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcr5ya4mxqKH"
      },
      "source": [
        "data = tf.constant(\n",
        "    [\n",
        "        \"The Brain is wider than the Sky\",\n",
        "        \"For put them side by side\",\n",
        "        \"The one the other will contain\",\n",
        "        \"With ease and You beside\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "text_vectorizer = preprocessing.TextVectorization(output_mode='int')\n",
        "text_vectorizer.adapt(data)\n",
        "\n",
        "vocab = text_vectorizer.get_vocabulary()\n",
        "print('Vecabulary: ', vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja2KanK421fu"
      },
      "source": [
        "inputs = keras.Input(shape=(1, ), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = keras.layers.Embedding(input_dim=len(vocab), output_dim=64)(x)\n",
        "outputs = layers.LSTM(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "test_data = tf.constant([\"The Brain is deeper than the sea\"])\n",
        "model(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKhJ8wVk33VG"
      },
      "source": [
        "data = tf.constant(\n",
        "    [\n",
        "        \"The Brain is wider than the Sky\",\n",
        "        \"For put them side by side\",\n",
        "        \"The one the other will contain\",\n",
        "        \"With ease and You beside\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "text_vectorizer = preprocessing.TextVectorization(output_mode='binary', ngrams=2)\n",
        "text_vectorizer.adapt(data)\n",
        "print(text_vectorizer.get_vocabulary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT-gi2Mg5mo_"
      },
      "source": [
        "print(\n",
        "    \"Encoded text:\\n\",\n",
        "    text_vectorizer([\"The Brain is deeper than the sea\"]).numpy(),\n",
        "    \"\\n\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPPlT_t_5v7-"
      },
      "source": [
        "inputs = keras.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "test_data = tf.constant([\"The Brain is deeper than the sea\"])\n",
        "test_output = model(test_data)\n",
        "print(test_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTOAs5T06F6e"
      },
      "source": [
        "data = tf.constant(\n",
        "    [\n",
        "        \"The Brain is wider than the Sky\",\n",
        "        \"For put them side by side\",\n",
        "        \"The one the other will contain\",\n",
        "        \"With ease and You beside\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "text_vectorizer = preprocessing.TextVectorization(output_mode='tf-idf', ngrams=2)\n",
        "text_vectorizer.adapt(data)\n",
        "print(\n",
        "    \"Encoded text:\\n\",\n",
        "    text_vectorizer([\"The Brain is deeper than the sea\"]).numpy(),\n",
        "    \"\\n\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z8abTLS6k7x"
      },
      "source": [
        "inputs = keras.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "outputs = keras.layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "test_data = tf.constant([\"The Brain is deeper than the sea\"])\n",
        "test_output = model(test_data)\n",
        "print(test_output.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}