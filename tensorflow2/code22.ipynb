{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPfL5vBMvc+C0tAJxNdUTn2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVoj6HSUYPjA"
      },
      "source": [
        "!pip install -q -U tensorflow-text\n",
        "!pip install -q -U tf-models-official\n",
        "!pip install -q -U tfds-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTUXhMQFbM4p"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from official.nlp import optimization\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eij-o8w8bU-s"
      },
      "source": [
        "os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW6BgbHXbcY_"
      },
      "source": [
        "if os.environ['COLAB_TPU_ADDR']:\n",
        "    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "    strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "    print(\"Using TPU\")\n",
        "elif tf.test.is_gpu_available():\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    raise ValueError('Running on CPU is not recommended')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0HP0V5zhjUA"
      },
      "source": [
        "bert_model_name = 'bert_en_uncased_L-12_H-768_A-12' \n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_uncased_L-24_H-1024_A-16':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_L-24_H-1024_A-16/3',\n",
        "    'bert_en_wwm_uncased_L-24_H-1024_A-16':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_wwm_uncased_L-24_H-1024_A-16/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-24_H-1024_A-16':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_cased_L-24_H-1024_A-16/3',\n",
        "    'bert_en_wwm_cased_L-24_H-1024_A-16':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_wwm_cased_L-24_H-1024_A-16/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/albert_en_base/2',\n",
        "    'albert_en_large':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/albert_en_large/2',\n",
        "    'albert_en_xlarge':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/albert_en_xlarge/2',\n",
        "    'albert_en_xxlarge':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/albert_en_xxlarge/2',\n",
        "    'electra_small':\n",
        "        'https://hub.tensorflow.google.cn/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://hub.tensorflow.google.cn/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://hub.tensorflow.google.cn/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://hub.tensorflow.google.cn/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "    'talking-heads_large':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/talkheads_ggelu_bert_en_large/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-24_H-1024_A-16':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_wwm_cased_L-24_H-1024_A-16':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'bert_en_cased_L-24_H-1024_A-16':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'bert_en_wwm_uncased_L-24_H-1024_A-16':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/albert_en_preprocess/3',\n",
        "    'albert_en_large':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/albert_en_preprocess/3',\n",
        "    'albert_en_xlarge':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/albert_en_preprocess/3',\n",
        "    'albert_en_xxlarge':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_large':\n",
        "        'https://hub.tensorflow.google.cn/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print('BERT model selected           :', tfhub_handle_encoder)\n",
        "print('Preprocessing model auto-selected:', tfhub_handle_preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84eGNtYciYeO"
      },
      "source": [
        "bert_preprocess = hub.load(tfhub_handle_preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKC5svjMjzy2"
      },
      "source": [
        "tok = bert_preprocess.tokenize(tf.constant(['Hello TensorFlow!']))\n",
        "tok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivMvXF2yj83a"
      },
      "source": [
        "text_preprocessed = bert_preprocess.bert_pack_inputs([tok, tok], tf.constant(20))\n",
        "text_preprocessed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrdrKDNDmOFG"
      },
      "source": [
        "print(text_preprocessed.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atbE-i2VmWAn"
      },
      "source": [
        "print('Shape of word ids: ', text_preprocessed['input_word_ids'].shape)\n",
        "print('Word ids         : ', text_preprocessed['input_word_ids'][0, :12])\n",
        "print('Shape of mask    : ', text_preprocessed['input_mask'].shape)\n",
        "print('Mask             : ', text_preprocessed['input_mask'][0, :12])\n",
        "print('Shape of type ids: ', text_preprocessed['input_type_ids'].shape)\n",
        "print('Type ids         : ', text_preprocessed['input_type_ids'][0, :12])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFk2tkVPnXit"
      },
      "source": [
        "def make_bert_preprocess_model(sentence_features, seq_length=128):\n",
        "    input_segments = [tf.keras.layers.Input((), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "\n",
        "    bert_preprocess = hub.load(tfhub_handle_preprocess)\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "\n",
        "    truncated_segments = segments\n",
        "\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs, arguments=dict(seq_length=seq_length), name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "\n",
        "    return tf.keras.Model(input_segments, model_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhKYuaRBKncu"
      },
      "source": [
        "test_preprocess_model = make_bert_preprocess_model(['input_1', 'input_2'])\n",
        "test_text1 = [np.array(['some random test sentence']), np.array(['another sentence'])]\n",
        "text_preprocessed = test_preprocess_model(test_text1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWNW0B42QwLZ"
      },
      "source": [
        "print(text_preprocessed.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSd-PFHSQ2rB"
      },
      "source": [
        "print('Shape of word ids: ', text_preprocessed['input_word_ids'].shape)\n",
        "print('Word ids         : ', text_preprocessed['input_word_ids'][0, :12])\n",
        "print('Shape of mask    : ', text_preprocessed['input_mask'].shape)\n",
        "print('Mask             : ', text_preprocessed['input_mask'][0, :12])\n",
        "print('Shape of type ids: ', text_preprocessed['input_type_ids'].shape)\n",
        "print('Type ids         : ', text_preprocessed['input_type_ids'][0, :12])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SlQDO9QQ7ut"
      },
      "source": [
        "tf.keras.utils.plot_model(test_preprocess_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyeo_et2RH2Q"
      },
      "source": [
        "test_preprocess_model2 = make_bert_preprocess_model(['input_1', 'input_2'])\n",
        "test_text2 = [np.array(['some random test sentence']), np.array(['another sentence'])]\n",
        "text_preprocessed2 = test_preprocess_model2(test_text2)\n",
        "\n",
        "print('Shape of word ids: ', text_preprocessed2['input_word_ids'].shape)\n",
        "print('Word ids         : ', text_preprocessed2['input_word_ids'][0, :16])\n",
        "print('Shape of mask    : ', text_preprocessed2['input_mask'].shape)\n",
        "print('Mask             : ', text_preprocessed2['input_mask'][0, :16])\n",
        "print('Shape of type ids: ', text_preprocessed2['input_type_ids'].shape)\n",
        "print('Type ids         : ', text_preprocessed2['input_type_ids'][0, :16])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iItAeWaqRhBF"
      },
      "source": [
        "def load_dataset_from_tfds(in_memory_ds, info, split, batch_size, bert_preprocess_model):\n",
        "    is_training = split.startswith('train')\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(in_memory_ds[split])\n",
        "    num_examples = info.splits[split].num_examples\n",
        "\n",
        "    if is_training:\n",
        "        dataset = dataset.shuffle(num_examples)\n",
        "        dataset = dataset.repeat()\n",
        "    \n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(lambda ex: (bert_preprocess_model(ex), ex['label']))\n",
        "    dataset = dataset.cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset, num_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHWGNqSDVacv"
      },
      "source": [
        "def build_classifier_model(num_classes):\n",
        "    inputs = dict(\n",
        "        input_word_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32),\n",
        "        input_mask = tf.keras.layers.Input((None,), dtype=tf.int32),\n",
        "        input_type_ids = tf.keras.layers.Input((None,), dtype=tf.int32),\n",
        "    )\n",
        "\n",
        "    encoder = hub.KerasLayer(tfhub_handle_encoder, True, name='encoder')\n",
        "\n",
        "    net = encoder(inputs)['pooled_output']\n",
        "    net = tf.keras.layers.Dropout(0.1)(net)\n",
        "    net = tf.keras.layers.Dense(num_classes, name='classifier')(net)\n",
        "\n",
        "    return tf.keras.Model(inputs, net, name='prediction')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZReOmYOeaY6m"
      },
      "source": [
        "test_classifier_model = build_classifier_model(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OmImDY4aeuC"
      },
      "source": [
        "text_preprocessed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6K4ZTZpaof6"
      },
      "source": [
        "bert_raw_result = test_classifier_model(text_preprocessed)\n",
        "print(tf.sigmoid(bert_raw_result))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFn1E-JRayWG"
      },
      "source": [
        "tf.keras.utils.plot_model(test_classifier_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x64IgkeCa--7"
      },
      "source": [
        "tfds_name = 'glue/cola'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvsv0zOCbe9U"
      },
      "source": [
        "tfds.builder(tfds_name).info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg1oUuTkbmn9"
      },
      "source": [
        "tfds_info = tfds.builder(tfds_name).info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnZ26EvQbtsK"
      },
      "source": [
        "sentence_features = list(tfds_info.features.keys())\n",
        "sentence_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QehkPDqEb-XM"
      },
      "source": [
        "sentence_features.remove('idx')\n",
        "sentence_features.remove('label')\n",
        "sentence_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu__s3nKdh9q"
      },
      "source": [
        "avaliable_splits = list(tfds_info.splits.keys())\n",
        "avaliable_splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgdnrL2Ud0Ir"
      },
      "source": [
        "train_split = 'train'\n",
        "validation_split = 'validation'\n",
        "test_split = 'test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dnea6IKd61U"
      },
      "source": [
        "if tfds_name == 'glue/mnli':\n",
        "    validation_split = 'validation_matched'\n",
        "    test_split = 'test_matched'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmse2FYreUDK"
      },
      "source": [
        "num_classes = tfds_info.features['label'].num_classes\n",
        "num_examples = tfds_info.splits.total_num_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ktJ3zJtesdP"
      },
      "source": [
        "print(f'Using {tfds_name} from TFDS')\n",
        "print(f'This dataset has {num_examples} examples')\n",
        "print(f'Number classes: {num_classes}')\n",
        "print(f'Features: {sentence_features}')\n",
        "print(f'Splits: {avaliable_splits}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsloqH7GfHHK"
      },
      "source": [
        "with tf.device('/job:localhost'):\n",
        "    in_memory_ds = tfds.load(tfds_name, batch_size=-1, shuffle_files=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmiqQiSlffa3"
      },
      "source": [
        "print(f'Here are some sample rows from {tfds_name} dataset')\n",
        "\n",
        "sample_dataset = tf.data.Dataset.from_tensor_slices(in_memory_ds[train_split])\n",
        "label_names = tfds_info.features['label'].names\n",
        "print(label_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ6ZkOpRhL_D"
      },
      "source": [
        "sample_dataset.take(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xb8Gqjdgvgi"
      },
      "source": [
        "sample_i = 1\n",
        "\n",
        "for sample_row in sample_dataset.take(5):\n",
        "    samples = [sample_row[feature] for feature in sentence_features]\n",
        "    print(f'sample row {sample_i}:')\n",
        "    for sample in samples:\n",
        "        print(sample)\n",
        "    \n",
        "    sample_label = sample_row['label']\n",
        "    print(f'label: {sample_label} ({label_names[sample_label]})')\n",
        "    print()\n",
        "    sample_i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU5q4mfTiVf8"
      },
      "source": [
        "def get_configuration(glue_task):\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(True)\n",
        "\n",
        "    if glue_task == 'glue/cola':\n",
        "        metrics = tfa.metrics.MatthewsCorrelationCoefficient(num_classes=2)\n",
        "    else:\n",
        "        metrics = tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)\n",
        "    \n",
        "    return metrics, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vYSb8BCkGAn"
      },
      "source": [
        "epochs=3\n",
        "batch_size=32\n",
        "init_lr=2e-5\n",
        "\n",
        "print(f'Fine tuning {tfhub_handle_encoder} model')\n",
        "bert_preprocess_model = make_bert_preprocess_model(sentence_features)\n",
        "tf.keras.utils.plot_model(bert_preprocess_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt1EPFdlk0cY"
      },
      "source": [
        "with strategy.scope():\n",
        "    metrics, loss = get_configuration(tfds_name)\n",
        "\n",
        "    train_dataset, train_data_size = load_dataset_from_tfds(in_memory_ds, tfds_info, train_split, batch_size, bert_preprocess_model)\n",
        "\n",
        "    steps_per_epoch = train_data_size // batch_size\n",
        "    num_train_steps = steps_per_epoch * epochs\n",
        "    num_warmup_steps = num_train_steps // 10\n",
        "\n",
        "    validation_dataset, validation_data_size = load_dataset_from_tfds(in_memory_ds, tfds_info, validation_split, batch_size, bert_preprocess_model)\n",
        "    validation_steps = validation_data_size // batch_size\n",
        "\n",
        "    classifier_model = build_classifier_model(num_classes)\n",
        "\n",
        "    optimizer = optimization.create_optimizer(init_lr, num_train_steps, num_warmup_steps)\n",
        "\n",
        "    classifier_model.compile(optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    classifier_model.fit(x=train_dataset, validation_data=validation_dataset, epochs=epochs, steps_per_epoch= steps_per_epoch, validation_steps=validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkHKozCqp9Hn"
      },
      "source": [
        "main_save_path = './my_models'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDsjU3vbruLJ"
      },
      "source": [
        "bert_type = tfhub_handle_encoder.split('/')[-2]\n",
        "saved_model_name = f\"{tfds_name.replace('/', '_')}_{bert_type}\"\n",
        "\n",
        "save_model_path = os.path.join(main_save_path, saved_model_name)\n",
        "save_model_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDgGDL50s8jZ"
      },
      "source": [
        "preprocess_inputs = bert_preprocess_model.inputs\n",
        "bert_encoder_inputs = bert_preprocess_model(preprocess_inputs)\n",
        "bert_outputs = classifier_model(bert_encoder_inputs)\n",
        "model_for_export = tf.keras.Model(preprocess_inputs, bert_outputs)\n",
        "\n",
        "print('Saving ', save_model_path)\n",
        "\n",
        "save_options = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
        "model_for_export.save(save_model_path, include_optimizer=False, options=save_options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZC2KB6At5xL"
      },
      "source": [
        "with tf.device('/job:localhost'):\n",
        "    reloaded_model = tf.saved_model.load(save_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLUmfRNfvy9u"
      },
      "source": [
        "def prepare(record):\n",
        "    model_inputs = [[record[ft]] for ft in sentence_features]\n",
        "    return model_inputs\n",
        "\n",
        "def prepare_serving(record):\n",
        "    model_inputs = {ft: record[ft] for ft in sentence_features}\n",
        "    return model_inputs\n",
        "\n",
        "def print_bert_results(test, bert_result, dataset_name):\n",
        "    bert_result_class = tf.argmax(bert_result, axis=1)[0]\n",
        "\n",
        "    if dataset_name == 'glue/cola':\n",
        "        print('sentence: ', test[0].numpy())\n",
        "        if bert_result_class == 1:\n",
        "            print('This sentence is Acceptable')\n",
        "        else:\n",
        "            print('This sentence is Unacceptable')\n",
        "    \n",
        "    elif dataset_name == 'glue/sst2':\n",
        "        print('sentence: ', test[0].numpy())\n",
        "        if bert_result_class == 1:\n",
        "            print('This sentence is POSITIVE')\n",
        "        else:\n",
        "            print('This sentence is NEGATIVE')\n",
        "    \n",
        "    elif dataset_name == 'glue/mrpc':\n",
        "        print('sentence1: ', test[0].numpy())\n",
        "        print('sentence2: ', test[1].numpy())\n",
        "        if bert_result_class == 1:\n",
        "            print('Are a paraphrase')\n",
        "        else:\n",
        "            print('Are NOT a paraphrase')\n",
        "    \n",
        "    elif dataset_name == 'glue/qqb':\n",
        "        print('question1: ', test[0].numpy())\n",
        "        print('question2: ', test[1].numpy())\n",
        "        if bert_result_class == 1:\n",
        "            print('Questions are similar')\n",
        "        else:\n",
        "            print('Questions are NOT similay')\n",
        "    \n",
        "    elif dataset_name == 'glue/mnli':\n",
        "        print('premise: ', test[0].numpy())\n",
        "        print('hypothesis: ', test[1].numpy())\n",
        "        if bert_result_class == 1:\n",
        "            print('This premise is NEUTRAL to the hypothesis')\n",
        "        elif bert_result_class == 2:\n",
        "            print('This premise is CONTRADICT to the hypothesis')\n",
        "        else:\n",
        "            print('This premise is ENTAILS to the hypothesis')\n",
        "    \n",
        "    elif dataset_name == 'glue/qnli':\n",
        "        print('question: ', test[0].numpy())\n",
        "        print('sentence: ', test[1].numpy())\n",
        "        if bert_result_class == 1:\n",
        "            print('This question is NOT answerable by the sentence')\n",
        "        else:\n",
        "            print('This question is answerable by the sentence')\n",
        "    \n",
        "    elif dataset_name == 'glue/rte':\n",
        "        print('sentence1: ', test[0].numpy())\n",
        "        print('sentence2: ', test[1].numpy())\n",
        "        if bert_result_class == 1:\n",
        "            print('sentence1 DOES NOT entail sentence2')\n",
        "        else:\n",
        "            print('sentence1 entail sentence2')\n",
        "\n",
        "    elif dataset_name == 'glue/wnli':\n",
        "        print('sentence1: ', test[0].numpy())\n",
        "        print('sentence2: ', test[1].numpy())\n",
        "        if bert_result_class == 1:\n",
        "            print('sentence1 DOES NOT entail sentence2')\n",
        "        else:\n",
        "            print('sentence1 entail sentence2')\n",
        "    \n",
        "    print('Bert raw results: ', bert_result[0])\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1csn8wv1E05"
      },
      "source": [
        "with tf.device('/job:localhost'):\n",
        "    test_dataset = tf.data.Dataset.from_tensor_slices(in_memory_ds[test_split])\n",
        "    for test_row in test_dataset.shuffle(1000).map(prepare).take(5):\n",
        "        if len(sentence_features) == 1:\n",
        "            result = reloaded_model(test_row[0])\n",
        "        else:\n",
        "            result = reloaded_model(list(test_row))\n",
        "        \n",
        "        print_bert_results(test_row, result, tfds_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPLxGqH73BSr"
      },
      "source": [
        "with tf.device('/job:localhost'):\n",
        "    serving_model = reloaded_model.signatures['serving_default']\n",
        "    for test_row in test_dataset.shuffle(1000).map(prepare_serving).take(5):\n",
        "        result = serving_model(**test_row)\n",
        "        # The 'prediction' key is the classifier's defined model name.\n",
        "        print_bert_results(list(test_row.values()), result['prediction'], tfds_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
