{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtl7z1esWFjkfm7GA2XIbO"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqH5G9XeMN5H"
      },
      "source": [
        "!pip install -q tf-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZgCt2ZPNJe-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjI_BFRXNfFA"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o-swLSXNijJ"
      },
      "source": [
        "tnp.experimental_enable_numpy_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_zOO6nnQFMM"
      },
      "source": [
        "ones = tnp.ones([5, 3], dtype=tnp.float32)\n",
        "print(\"Create a ND array with shape = {}, rank = {}, dtype = {} on device {}\".format(ones.shape, ones.ndim, ones.dtype, ones.device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6-GQbTxa04o"
      },
      "source": [
        "print(ones.T)\n",
        "print(ones.T.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-e4Tq_0bEsg"
      },
      "source": [
        "print(ones.reshape(-1).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqdUSz9JbPDL"
      },
      "source": [
        "print(\"Type promotion for opertion:\")\n",
        "values = [tnp.asarray(1, dtype=d) for d in (tnp.int32, tnp.int64, tnp.float32, tnp.float64)]\n",
        "\n",
        "for i, v1 in enumerate(values):\n",
        "    for v2 in values[i + 1:]:\n",
        "        print(\"%s + %s = %s\" % (v1.dtype.name, v2.dtype.name, (v1 + v2).dtype.name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7ILUp7DfUKz"
      },
      "source": [
        "print(\"Type inference during array creation\")\n",
        "print(\"tnp.asarray(1).dtype == tnp.%s\" % tnp.asarray(1).dtype.name)\n",
        "print(\"tnp.asarray(1.).dtype == tnp.%s\\n\" % tnp.asarray(1.).dtype.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJPEXjDzfpbc"
      },
      "source": [
        "tnp.experimental_enable_numpy_behavior(prefer_float32=True)\n",
        "print(\"When prefer_float32 is True:\")\n",
        "print(\"tnp.asarray(1.).dtype == tnp.%s\" % tnp.asarray(1.).dtype.name)\n",
        "print(\"tnp.add(1., 2.).dtype == tnp.%s\" % tnp.add(1., 2.).dtype.name)\n",
        "\n",
        "tnp.experimental_enable_numpy_behavior(prefer_float32=False)\n",
        "print(\"When prefer_float32 is False:\")\n",
        "print(\"tnp.asarray(1.).dtype == tnp.%s\" % tnp.asarray(1.).dtype.name)\n",
        "print(\"tnp.add(1., 2.).dtype == tnp.%s\" % tnp.add(1., 2.).dtype.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5cnVWIUwsCE"
      },
      "source": [
        "x = tnp.ones([2, 3])\n",
        "y = tnp.ones([3])\n",
        "z = tnp.ones([1, 2, 1])\n",
        "print(\"Broadcasting shapes %s, %s and %s gives shape %s\" % (\n",
        "    x.shape, y.shape, z.shape, (x + y + z).shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyOYElznw6lz"
      },
      "source": [
        "x = tnp.arange(24).reshape(2, 3, 4)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vRE_oWWxX4c"
      },
      "source": [
        "print(\"Basic indexing\")\n",
        "print(x[1, tnp.newaxis, 1:3, ...], \"\\n\")\n",
        "\n",
        "print(\"Boolean indexing\")\n",
        "print(x[:, (True, False, True)], \"\\n\")\n",
        "\n",
        "print(\"Advanced indexing\")\n",
        "print(x[1, (0, 0, 1), tnp.asarray([0, 1, 1])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drtLg9ooxeGK"
      },
      "source": [
        "try:\n",
        "  tnp.arange(6)[1] = -1\n",
        "except TypeError:\n",
        "  print(\"Currently, TensorFlow NumPy does not support mutation.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97FeF-a6x2ID"
      },
      "source": [
        "class Model(object):\n",
        "    def __init__(self):\n",
        "        self.weights = None\n",
        "    \n",
        "    def predict(self, inputs):\n",
        "        if self.weights is None:\n",
        "            size = inputs.shape[1]\n",
        "\n",
        "            stddev = tnp.sqrt(size).astype(tnp.float32)\n",
        "            w1 = tnp.random.randn(size, 64).astype(tnp.float32) / stddev\n",
        "            bias = tnp.random.randn(64).astype(tnp.float32)\n",
        "            w2 = tnp.random.randn(64, 2)\n",
        "\n",
        "            self.weights = (w1, bias, w2)\n",
        "        else:\n",
        "            w1, bias, w2 = self.weights\n",
        "        \n",
        "        y = tnp.matmul(inputs, w1) + bias\n",
        "        y = tnp.maximum(y, 0)  # relu\n",
        "        return tnp.matmul(y, w2)\n",
        "\n",
        "model = Model()\n",
        "print(model.predict(tnp.ones([2, 32], dtype=tnp.float32)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfsSCYiR2dL_"
      },
      "source": [
        "np_sum = np.sum(tnp.ones([2, 3]))\n",
        "tnp_sum = tnp.sum(np.ones([2, 3]))\n",
        "\n",
        "print(\"Sum = %s, Class = %s\" % (float(np_sum), np_sum.__class__))\n",
        "print(\"Sum = %s, Class = %s\" % (float(tnp_sum), tnp_sum.__class__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lcQuzHY32l7"
      },
      "source": [
        "labels = 15 + 2 * tnp.random.randn(1, 1000)\n",
        "_ = plt.hist(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlHpbkNU4ETJ"
      },
      "source": [
        "x = tnp.ones([2]) + np.ones([2])\n",
        "print(\"x = %s\\nclass = %s\" % (x, x.__class__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Vw-1Tm6D9P"
      },
      "source": [
        "x = tf.constant([1, 2])\n",
        "print(x)\n",
        "\n",
        "# `asarray` and `convert_to_tensor` here are no-ops.\n",
        "tnp_x = tnp.asarray(x)\n",
        "print(tnp_x)\n",
        "print(tf.convert_to_tensor(tnp_x))\n",
        "\n",
        "# Note that tf.Tensor.numpy() will continue to return `np.ndarray`.\n",
        "print(x.numpy(), x.numpy().__class__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KgdkvXv6bZa"
      },
      "source": [
        "# ND array passed into TensorFlow function.\n",
        "tf_sum = tf.reduce_sum(tnp.ones([2, 3], tnp.float32))\n",
        "print(\"Output = %s\" % tf_sum)\n",
        "\n",
        "# `tf.Tensor` passed into TensorFlow NumPy function.\n",
        "tnp_sum = tnp.sum(tf.ones([2, 3]))\n",
        "print(\"Output = %s\" % tnp_sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmZ8IFkf7TEN"
      },
      "source": [
        "def create_batch(batch_size=32):\n",
        "    return (tnp.random.randn(batch_size, 32).astype(tnp.float32), tnp.random.randn(batch_size, 2).astype(tnp.float32))\n",
        "\n",
        "def compute_gradients(model, inputs, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(model.weights)\n",
        "\n",
        "        prediction = model.predict(inputs)\n",
        "\n",
        "        loss = tnp.sum(tnp.square(prediction - labels))\n",
        "\n",
        "    return tape.gradient(loss, model.weights)\n",
        "\n",
        "inputs, labels = create_batch()\n",
        "gradients = compute_gradients(model, inputs, labels)\n",
        "\n",
        "print(\"Parameter shapes:\", [w.shape for w in model.weights])\n",
        "print(\"Gradient shapes:\", [g.shape for g in gradients])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcqfewGE-jAG"
      },
      "source": [
        "def prediction_batch_jacobian(inputs):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(inputs)\n",
        "    prediction = model.predict(inputs)\n",
        "  return prediction, tape.batch_jacobian(prediction, inputs)\n",
        "\n",
        "inp_batch = tnp.ones([16, 32], tnp.float32)\n",
        "output, batch_jacobian = prediction_batch_jacobian(inp_batch)\n",
        "# Note how the batch jacobian shape relates to the input and output shapes.\n",
        "print(\"Output shape: %s, input shape: %s\" % (output.shape, inp_batch.shape))\n",
        "print(\"Batch jacobian shape:\", batch_jacobian.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NZjNcqe-1df"
      },
      "source": [
        "inputs, labels = create_batch(512)\n",
        "print(\"Eager performante:\")\n",
        "compute_gradients(model, inputs, labels)\n",
        "print(timeit.timeit(lambda: compute_gradients(model, inputs, labels), number=10) * 100, 'ms')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLyjJJqdDsq2"
      },
      "source": [
        "print(\"tf function performance:\")\n",
        "compile_compute_gradients = tf.function(compute_gradients)\n",
        "compile_compute_gradients(model, inputs, labels)\n",
        "print(timeit.timeit(lambda: compile_compute_gradients(model, inputs, labels), number=10) * 100, 'ms')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5XxL1BgEGmz"
      },
      "source": [
        "@tf.function\n",
        "def vectorized_per_example_gradients(inputs, labels):\n",
        "  def single_example_gradient(arg):\n",
        "    inp, label = arg\n",
        "    return compute_gradients(model,\n",
        "                             tnp.expand_dims(inp, 0),\n",
        "                             tnp.expand_dims(label, 0))\n",
        "  # Note that a call to `tf.vectorized_map` semantically maps\n",
        "  # `single_example_gradient` over each row of `inputs` and `labels`.\n",
        "  # The interface is similar to `tf.map_fn`.\n",
        "  # The underlying machinery vectorizes away this map loop which gives\n",
        "  # nice speedups.\n",
        "  return tf.vectorized_map(single_example_gradient, (inputs, labels))\n",
        "\n",
        "batch_size = 128\n",
        "inputs, labels = create_batch(batch_size)\n",
        "\n",
        "per_example_gradients = vectorized_per_example_gradients(inputs, labels)\n",
        "for w, p in zip(model.weights, per_example_gradients):\n",
        "  print(\"Weight shape: %s, batch size: %s, per example gradient shape: %s \" % (\n",
        "      w.shape, batch_size, p.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GoCxK1dBfx_"
      },
      "source": [
        "@tf.function\n",
        "def unvectorized_per_example_gradients(inputs, labels):\n",
        "  def single_example_gradient(arg):\n",
        "    inp, label = arg\n",
        "    return compute_gradients(model,\n",
        "                             tnp.expand_dims(inp, 0),\n",
        "                             tnp.expand_dims(label, 0))\n",
        "\n",
        "  return tf.map_fn(single_example_gradient, (inputs, labels),\n",
        "                   fn_output_signature=(tf.float32, tf.float32, tf.float32))\n",
        "\n",
        "print(\"Running vectorized computation\")\n",
        "print(timeit.timeit(lambda: vectorized_per_example_gradients(inputs, labels),\n",
        "                    number=10) * 100, \"ms\")\n",
        "\n",
        "print(\"\\nRunning unvectorized computation\")\n",
        "per_example_gradients = unvectorized_per_example_gradients(inputs, labels)\n",
        "print(timeit.timeit(lambda: unvectorized_per_example_gradients(inputs, labels),\n",
        "                    number=10) * 100, \"ms\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZSJjlurBkY5"
      },
      "source": [
        "print(\"All logical devices:\", tf.config.list_logical_devices())\n",
        "print(\"All physical devices:\", tf.config.list_physical_devices())\n",
        "\n",
        "# Try to get the GPU device. If unavailable, fallback to CPU.\n",
        "try:\n",
        "  device = tf.config.list_logical_devices(device_type=\"GPU\")[0]\n",
        "except IndexError:\n",
        "  device = \"/device:CPU:0\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_9c5GiBBnLc"
      },
      "source": [
        "print(\"Using device: %s\" % str(device))\n",
        "# Run operations in the `tf.device` scope.\n",
        "# If a GPU is available, these operations execute on the GPU and outputs are\n",
        "# placed on the GPU memory.\n",
        "with tf.device(device):\n",
        "  prediction = model.predict(create_batch(5)[0])\n",
        "\n",
        "print(\"prediction is placed on %s\" % prediction.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW4dO6imBpfS"
      },
      "source": [
        "with tf.device(\"/device:CPU:0\"):\n",
        "  prediction_cpu = tnp.copy(prediction)\n",
        "print(prediction.device)\n",
        "print(prediction_cpu.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59vl96GkBrvW"
      },
      "source": [
        "def benchmark(f, inputs, number=30, force_gpu_sync=False):\n",
        "  \"\"\"Utility to benchmark `f` on each value in `inputs`.\"\"\"\n",
        "  times = []\n",
        "  for inp in inputs:\n",
        "    def _g():\n",
        "      if force_gpu_sync:\n",
        "        one = tnp.asarray(1)\n",
        "      f(inp)\n",
        "      if force_gpu_sync:\n",
        "        with tf.device(\"CPU:0\"):\n",
        "          tnp.copy(one)  # Force a sync for GPU case\n",
        "\n",
        "    _g()  # warmup\n",
        "    t = timeit.timeit(_g, number=number)\n",
        "    times.append(t * 1000. / number)\n",
        "  return times\n",
        "\n",
        "\n",
        "def plot(np_times, tnp_times, compiled_tnp_times, has_gpu, tnp_times_gpu):\n",
        "  \"\"\"Plot the different runtimes.\"\"\"\n",
        "  plt.xlabel(\"size\")\n",
        "  plt.ylabel(\"time (ms)\")\n",
        "  plt.title(\"Sigmoid benchmark: TF NumPy vs NumPy\")\n",
        "  plt.plot(sizes, np_times, label=\"NumPy\")\n",
        "  plt.plot(sizes, tnp_times, label=\"TF NumPy (CPU)\")\n",
        "  plt.plot(sizes, compiled_tnp_times, label=\"Compiled TF NumPy (CPU)\")\n",
        "  if has_gpu:\n",
        "    plt.plot(sizes, tnp_times_gpu, label=\"TF NumPy (GPU)\")\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlg5zPXqBvPh"
      },
      "source": [
        "def np_sigmoid(y):\n",
        "  return 1. / (1. + np.exp(-y))\n",
        "\n",
        "def tnp_sigmoid(y):\n",
        "  return 1. / (1. + tnp.exp(-y))\n",
        "\n",
        "@tf.function\n",
        "def compiled_tnp_sigmoid(y):\n",
        "  return tnp_sigmoid(y)\n",
        "\n",
        "sizes = (2 ** 0, 2 ** 5, 2 ** 10, 2 ** 15, 2 ** 20)\n",
        "np_inputs = [np.random.randn(size).astype(np.float32) for size in sizes]\n",
        "np_times = benchmark(np_sigmoid, np_inputs)\n",
        "\n",
        "with tf.device(\"/device:CPU:0\"):\n",
        "  tnp_inputs = [tnp.random.randn(size).astype(np.float32) for size in sizes]\n",
        "  tnp_times = benchmark(tnp_sigmoid, tnp_inputs)\n",
        "  compiled_tnp_times = benchmark(compiled_tnp_sigmoid, tnp_inputs)\n",
        "\n",
        "has_gpu = len(tf.config.list_logical_devices(\"GPU\"))\n",
        "if has_gpu:\n",
        "  with tf.device(\"/device:GPU:0\"):\n",
        "    tnp_inputs = [tnp.random.randn(size).astype(np.float32) for size in sizes]\n",
        "    tnp_times_gpu = benchmark(compiled_tnp_sigmoid, tnp_inputs, 100, True)\n",
        "else:\n",
        "  tnp_times_gpu = None\n",
        "plot(np_times, tnp_times, compiled_tnp_times, has_gpu, tnp_times_gpu)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}