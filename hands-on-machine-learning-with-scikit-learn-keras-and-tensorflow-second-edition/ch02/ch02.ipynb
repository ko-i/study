{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "ch02.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNSt1ckaZoLF"
      },
      "source": [
        "# 2020-10-21 created by Akson"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV604XSWertB"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url = HOUSING_URL, housing_path = HOUSING_PATH):\n",
        "    os.makedirs(housing_path, exist_ok = True)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path = housing_path)\n",
        "    housing_tgz.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZmegevQhiSB"
      },
      "source": [
        "fetch_housing_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPAkp5nzZoLM"
      },
      "source": [
        "# Code2.1\n",
        "# 加载数据\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# housing = pd.read_csv('/content/drive/MyDrive/datasets/housing/housing.csv')\n",
        "def load_housing_data(housing_path = HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRud6JZ3emxx"
      },
      "source": [
        "housing = load_housing_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F07XFxrZoLN"
      },
      "source": [
        "# Code2.2\n",
        "# 显示头五行数据\n",
        "\n",
        "housing.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZP625hCZoLN"
      },
      "source": [
        "# Code2.3\n",
        "# 显示info\n",
        "\n",
        "housing.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzHyM0alZoLO"
      },
      "source": [
        "# Code2.4\n",
        "# 检视'ocean_proximity'列\n",
        "\n",
        "print(housing['ocean_proximity'].value_counts())\n",
        "print(housing['ocean_proximity'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To2rffKvZoLO"
      },
      "source": [
        "# Code2.5\n",
        "# 试试.describe()\n",
        "\n",
        "housing.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNZGB7tQZoLO"
      },
      "source": [
        "# Code2.6\n",
        "# 绘制每种属性的直方图\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "housing.hist(bins = 50, figsize = (20, 15))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VklbqqZcZoLP"
      },
      "source": [
        "# Code2.7\n",
        "# 随机拆分数据集\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(housing, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ABcK2Q5ZoLP"
      },
      "source": [
        "# Code2.8\n",
        "# 收入数据分层\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "housing['income_cat'] = pd.cut(housing['median_income'], bins = [0., 1.5, 3.0, 4.5, 6.0, np.inf], labels = [1, 2, 3, 4, 5])\n",
        "housing['income_cat'].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGWNG7LrZoLQ"
      },
      "source": [
        "# Code2.9\n",
        "# 分层抽样\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\n",
        "\n",
        "for train_index, test_index in split.split(housing, housing['income_cat']):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]\n",
        "\n",
        "# strat_train_set\n",
        "# strat_train_set['income_cat'].value_counts() / len(strat_train_set)\n",
        "\n",
        "# 用完就丢，您可真是个带恶人\n",
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop('income_cat', axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EveGNh_lZoLQ"
      },
      "source": [
        "# Code2.10\n",
        "# 详细探究数据\n",
        "\n",
        "# 为了能随意操作数据而不影响原数据集，创建一个副本（得益于这个数据集较小，大数据及要慎重）\n",
        "housing = strat_train_set.copy()\n",
        "\n",
        "housing.plot(kind = 'scatter', x = 'longitude', y = 'latitude', alpha = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPbZatWfZoLQ"
      },
      "source": [
        "# Code2.11\n",
        "# 再加上房价与人口因素\n",
        "\n",
        "housing.plot(kind = 'scatter', x = 'longitude', y = 'latitude', alpha = 0.4, s = housing['population'] / 100, label = 'population', figsize = (10, 7), c = 'median_house_value', cmap = plt.get_cmap('jet'), colorbar = True)\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OAX0wo4ZoLQ"
      },
      "source": [
        "# Code2.12\n",
        "# 计算每对属性的相关系数，并提取出与房价有关的信息\n",
        "\n",
        "corr_matrix = housing.corr()\n",
        "\n",
        "corr_matrix['median_house_value'].sort_values(ascending = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua6LWJrxZoLR"
      },
      "source": [
        "# Code2.13\n",
        "# 使用pandas.scatter_matrix\n",
        "\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "attributes = ['median_house_value', 'median_income', 'total_rooms', 'housing_median_age']\n",
        "scatter_matrix(housing[attributes], figsize = (12, 8))\n",
        "\n",
        "# 也可以都输出试试\n",
        "# scatter_matrix(housing[:], figsize = (12, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni5qT5OYZoLR"
      },
      "source": [
        "# Code2.14\n",
        "# 看看感觉上与房价最相关的收入中位数\n",
        "\n",
        "housing.plot(kind = 'scatter', x = 'median_income', y = 'median_house_value', alpha = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QgTeBPbZoLR"
      },
      "source": [
        "# Code2.15\n",
        "# 根据存在的各种特征信息组合看看能不能导出其它更加有意义的特征\n",
        "\n",
        "housing['rooms_per_household'] = housing['total_rooms'] / housing['households']\n",
        "housing['bedrooms_per_room'] = housing['total_bedrooms'] / housing['total_rooms']\n",
        "housing['population_per_household'] = housing['population'] / housing['households']\n",
        "\n",
        "corr_matrix = housing.corr()\n",
        "corr_matrix['median_house_value'].sort_values(ascending = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drVsKhmOZoLR"
      },
      "source": [
        "# Code2.16\n",
        "# 处理缺失数据（pandas提供的方法，丢弃缺失的部分）\n",
        "\n",
        "# 从数据集中去除作为标签的数据\n",
        "housing = strat_train_set.drop('median_house_value', axis = 1)\n",
        "\n",
        "housing.dropna(subset = ['total_bedrooms'])  # 丢弃缺失数据的部分"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM0-ZGjIZoLS"
      },
      "source": [
        "# Code2.17\n",
        "# 处理缺失数据（pandas提供的方法，丢弃整个属性）\n",
        "\n",
        "# 从数据集中去除作为标签的数据\n",
        "housing = strat_train_set.drop('median_house_value', axis = 1)\n",
        "\n",
        "housing.drop('total_bedrooms', axis = 1)  # 丢弃整个‘total_bedrooms’属性"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTJidPioZoLS"
      },
      "source": [
        "# Code2.18\n",
        "# 处理缺失数据（pandas提供的方法，用中位数填补）\n",
        "\n",
        "# 从数据集中去除作为标签的数据\n",
        "housing = strat_train_set.drop('median_house_value', axis = 1)\n",
        "\n",
        "# 使用中位数填充（也可以是其它值）\n",
        "median = housing['total_bedrooms'].median()\n",
        "housing['total_bedrooms'].fillna(median, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxoOdfb1ZoLS"
      },
      "source": [
        "# Code2.19\n",
        "# 处理缺失数据（使用sklearn提供的方法）\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# 从数据集中去除作为标签的数据\n",
        "housing = strat_train_set.drop('median_house_value', axis = 1)\n",
        "\n",
        "# 由于SimpleImputer只能操作数字，所以还要将数据中的非数字列去掉\n",
        "housing_num = housing.drop('ocean_proximity', axis = 1)\n",
        "\n",
        "# 定义转换器对象\n",
        "imputer = SimpleImputer(strategy = 'median')\n",
        "# 用转换器对象适配数据\n",
        "imputer.fit(housing_num)\n",
        "\n",
        "print(imputer.statistics_)\n",
        "print(housing_num.median().values)\n",
        "\n",
        "# 转换数据\n",
        "X = imputer.transform(housing_num)\n",
        "\n",
        "print(type(X))\n",
        "# 也可将其转换回pandas.dataFrame\n",
        "housing_tr = pd.DataFrame(X, columns = housing_num.columns, index = housing_num.index)\n",
        "print(type(housing_tr))\n",
        "print(type(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3KzPwNZZoLT"
      },
      "source": [
        "# Code2.20\n",
        "# 研究一下文本数据类型（或将其转换为数值型）\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# 从数据集中将文本数据分离出来\n",
        "housing = strat_train_set.drop('median_house_value', axis = 1)\n",
        "housing_cat = housing[['ocean_proximity']]\n",
        "\n",
        "print(housing_cat.head(10))\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
        "print(housing_cat_encoded[: 10])\n",
        "\n",
        "print(ordinal_encoder.categories_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMRlB4VdZoLT"
      },
      "source": [
        "# Code2.21\n",
        "# 还是使用独热（one-hot）编码好一些？\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# 从数据集中将文本数据分离出来\n",
        "housing = strat_train_set.drop('median_house_value', axis = 1)\n",
        "housing_cat = housing[['ocean_proximity']]\n",
        "\n",
        "cat_encoder = OneHotEncoder()\n",
        "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "print(type(housing_cat_1hot))\n",
        "\n",
        "# 也可以尝试将此稀疏矩阵转换成密集矩阵，但数据量大时最好不要这么做\n",
        "# print(housing_cat_1hot.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCxs1cEOZoLT"
      },
      "source": [
        "# Code2.22\n",
        "# 自定义转换器\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
        "\n",
        "# 实现之前Code2.15功能的自定义转换器\n",
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, add_bedrooms_per_room = True):\n",
        "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "    \n",
        "    #  定义fit方法\n",
        "    def fit(self, X, y = None):\n",
        "        return self\n",
        "    \n",
        "    #  定义transform方法\n",
        "    def transform(self, X):\n",
        "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
        "        population_per_room = X[:, population_ix] / X[:, households_ix]\n",
        "        \n",
        "        if self.add_bedrooms_per_room:\n",
        "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
        "            return np.c_[X, rooms_per_household, population_per_room, bedrooms_per_room]\n",
        "        else:\n",
        "            return np.c_[X, rooms_per_household, population_per_room]    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p2UwKvmZoLT"
      },
      "source": [
        "# Code2.23\n",
        "# 自定义转换器测试\n",
        "\n",
        "# 从数据集中将文本数据分离出来\n",
        "housing = strat_train_set.drop('median_house_value', axis = 1)\n",
        "\n",
        "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room = False)\n",
        "housing_extra_attribs = attr_adder.transform(housing.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vagk8uNGZoLU"
      },
      "source": [
        "# Code2.24\n",
        "# 试试使用流水线工具\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy = 'median')),\n",
        "    ('attribs_adder', CombinedAttributesAdder()),\n",
        "    ('std_scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "# 从数据集中去除作为标签的数据\n",
        "housing = strat_train_set.drop('median_house_value', axis = 1)\n",
        "\n",
        "# 将数据中的非数字列去掉\n",
        "housing_num = housing.drop('ocean_proximity', axis = 1)\n",
        "\n",
        "# 测试一下咱们自己定义的流水线工具\n",
        "housing_num_tr = num_pipeline.fit_transform(housing_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbhHnMzPZoLU"
      },
      "source": [
        "# Code2.25\n",
        "# 使用ColumnTransformer\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# 从数据集中去除作为标签的数据\n",
        "housing = strat_train_set.drop('median_house_value', axis = 1)\n",
        "\n",
        "# 将数据中的非数字列去掉\n",
        "housing_num = housing.drop('ocean_proximity', axis = 1)\n",
        "\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = ['ocean_proximity']\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "    ('num', num_pipeline, num_attribs),\n",
        "    ('cat', OneHotEncoder(), cat_attribs),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1QBH5YoZoLU"
      },
      "source": [
        "# Code2.26\n",
        "# 使用前面分层抽样的结果做训练数据集准备\n",
        "\n",
        "housing = strat_train_set.drop('median_house_value', axis = 1)\n",
        "X_train = full_pipeline.fit_transform(housing)\n",
        "y_train = strat_train_set['median_house_value'].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIMnqAK-ZoLU"
      },
      "source": [
        "# Code2.27\n",
        "# 终于可以开始训练模型了！先使用LR试试\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "housing_predictions = lin_reg.predict(X_train)\n",
        "lin_mse = mean_squared_error(y_train, housing_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "lin_rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVhEqxJ7ZoLV"
      },
      "source": [
        "# Code2.28\n",
        "# 试试更为复杂的模型\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor()\n",
        "tree_reg.fit(X_train, y_train)\n",
        "\n",
        "housing_predictions = tree_reg.predict(X_train)\n",
        "tree_mse = mean_squared_error(y_train, housing_predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "tree_rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cQBCD3GZoLV"
      },
      "source": [
        "# Code2.29\n",
        "# 使用k折交叉验证的方法\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# sklearn自带的函数很方便，一行代码就搞定\n",
        "scores = cross_val_score(tree_reg, X_train, y_train, scoring = 'neg_mean_squared_error', cv = 10)\n",
        "tree_rmse_scores = np.sqrt(-scores)\n",
        "\n",
        "print('Scores: %s' % tree_rmse_scores)\n",
        "print('Mean: %s' % tree_rmse_scores.mean())\n",
        "print('Standard deviation: %s' % tree_rmse_scores.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM1-OU-YZoLV"
      },
      "source": [
        "# Code2.30\n",
        "# 再用线性模型测试一下交叉验证的结果\n",
        "\n",
        "scores = cross_val_score(lin_reg, X_train, y_train, scoring = 'neg_mean_squared_error', cv = 10)\n",
        "lin_rmse_scores = np.sqrt(-scores)\n",
        "\n",
        "print('Scores: %s' % lin_rmse_scores)\n",
        "print('Mean: %s' % lin_rmse_scores.mean())\n",
        "print('Standard deviation: %s' % lin_rmse_scores.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "che5mWcOZoLW"
      },
      "source": [
        "# Code2.31\n",
        "# 决策树明显过拟合了，使用随机森林的方法试试\n",
        "# 会运行一分钟左右\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor()\n",
        "forest_reg.fit(X_train, y_train)\n",
        "\n",
        "scores = cross_val_score(forest_reg, X_train, y_train, scoring = 'neg_mean_squared_error', cv = 10)\n",
        "forest_rmse_scores = np.sqrt(-scores)\n",
        "\n",
        "print('Scores: %s' % forest_rmse_scores)\n",
        "print('Mean: %s' % forest_rmse_scores.mean())\n",
        "print('Standard deviation: %s' % forest_rmse_scores.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsjOCwIAZoLW"
      },
      "source": [
        "# Code2.32\n",
        "# 使用网格搜索自动寻找最优超参数\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 设置需要测试的超参数值\n",
        "param_grid = [\n",
        "    {\n",
        "        'n_estimators' : [3, 10, 30],\n",
        "        'max_features': [2, 4, 6, 8],\n",
        "    },\n",
        "    {\n",
        "        'bootstrap': [False],\n",
        "        'n_estimators': [3, 10],\n",
        "        'max_features': [2, 3, 4]\n",
        "    }\n",
        "]\n",
        "\n",
        "forest_reg = RandomForestRegressor()\n",
        "grid_search = GridSearchCV(forest_reg, param_grid, cv = 5, scoring = 'neg_mean_squared_error', verbose = 1, n_jobs = -1, return_train_score = True)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fLK--iDZoLX"
      },
      "source": [
        "# Code 2.33\n",
        "# 分析结果\n",
        "\n",
        "# 输出最佳参数\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_estimator_)\n",
        "\n",
        "# 输出分数\n",
        "cvres = grid_search.cv_results_\n",
        "for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
        "    print(np.sqrt(-mean_score), params)\n",
        "\n",
        "# 分析每个属性的重要程度\n",
        "feature_importances = grid_search.best_estimator_.feature_importances_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLYKzULnMH_j"
      },
      "source": [
        "# Code 2.33续\n",
        "\n",
        "# 让输出结果好看些\n",
        "extra_attribs = ['room_per_hhold', 'pop_per_hhold', 'bedrooms_per_room']\n",
        "cat_encoder = full_pipeline.named_transformers_['cat']\n",
        "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
        "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
        "\n",
        "sorted(zip(feature_importances, attributes), reverse = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYpDk6uPZoLX"
      },
      "source": [
        "# Code2.34\n",
        "# 用测试集评估\n",
        "\n",
        "# 获取最佳模型\n",
        "final_model = grid_search.best_estimator_\n",
        "\n",
        "X_test = strat_test_set.drop('median_house_value', axis = 1)\n",
        "y_test = strat_test_set['median_house_value'].copy()\n",
        "\n",
        "X_test = full_pipeline.transform(X_test)\n",
        "\n",
        "predictions = final_model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "print(rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9eKyyckZoLX"
      },
      "source": [
        "# Code2.35\n",
        "# 计算一下当前计算误差的95%置信区间\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "confidence = 0.95\n",
        "\n",
        "squared_errors = (predictions - y_test) ** 2\n",
        "\n",
        "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1, loc = squared_errors.mean(), scale = stats.sem(squared_errors)))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}