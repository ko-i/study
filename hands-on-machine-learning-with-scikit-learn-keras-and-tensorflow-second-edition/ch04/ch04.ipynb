{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "ch04.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGg5eR-kn9Ko"
      },
      "source": [
        "# 2020-10-22 created by Akson"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-l5YZKKn9Kq"
      },
      "source": [
        "# Code4.1\n",
        "# 生成一些测试数据\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_TEUWVyn9Kr"
      },
      "source": [
        "# Code4.2\n",
        "# 画一下\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X, y)\n",
        "plt.axis([0, 2, 0, 15])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7lXA_gCn9Kr"
      },
      "source": [
        "# Code4.3\n",
        "# 使用标准方程计算\n",
        "\n",
        "X_b = np.c_[np.ones((100, 1)), X]\n",
        "# print(X_b)\n",
        "\n",
        "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
        "print(theta_best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrbnedQDn9Ks"
      },
      "source": [
        "# Code4.4\n",
        "# 预测新值\n",
        "\n",
        "X_new = np.array([[0], [2]])\n",
        "X_new_b = np.c_[np.ones((2, 1)), X_new]\n",
        "y_predict = X_new_b.dot(theta_best)\n",
        "print(y_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MBJQgQdn9Ks"
      },
      "source": [
        "# Code4.5\n",
        "# 画一下\n",
        "\n",
        "plt.plot(X_new, y_predict, 'r-')\n",
        "plt.plot(X, y, 'b.')\n",
        "plt.axis([0, 2, 0, 15])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NGKjzn23n9Ks"
      },
      "source": [
        "# Code4.6\n",
        "# 使用sklearn的线性回归模型\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X, y)\n",
        "\n",
        "print(lin_reg.intercept_)\n",
        "print(lin_reg.coef_)\n",
        "\n",
        "predictions = lin_reg.predict(X_new)\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwCzfkMQn9Kt"
      },
      "source": [
        "# Code4.7\n",
        "# sklearn使用的是这个最小二乘法函数，我们也可以直接调用它\n",
        "\n",
        "theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b, y, rcond = 1e-6)\n",
        "\n",
        "print(theta_best_svd)\n",
        "\n",
        "# 也可以掉用计算伪逆这个函数\n",
        "print(np.linalg.pinv(X_b).dot(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__E8UZw1n9Kt"
      },
      "source": [
        "# Code4.8\n",
        "# 手写批量梯度下降算法\n",
        "\n",
        "eta = 0.1\n",
        "n_iteration = 1000\n",
        "m = 100\n",
        "\n",
        "theta = np.random.randn(2, 1)\n",
        "\n",
        "for iteration in range(n_iteration):\n",
        "    gradients = 2 / m * X_b.T.dot(X_b.dot(theta) - y)\n",
        "    theta = theta - eta * gradients\n",
        "    \n",
        "print(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLHyaWzvn9Kt"
      },
      "source": [
        "# Code4.9\n",
        "# 手写随机梯度下降与模拟退火\n",
        "\n",
        "theta_path_sgd = []\n",
        "m = len(X_b)\n",
        "\n",
        "n_epochs = 50\n",
        "t0, t1 = 5, 50\n",
        "\n",
        "def learning_schedule(t):\n",
        "    return t0 / (t + t1)\n",
        "\n",
        "theta = np.random.randn(2, 1)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i in range(m):\n",
        "        if epoch == 0 and i < 20:\n",
        "            y_predict = X_new_b.dot(theta)\n",
        "            style = 'b-' if i > 0 else 'r--'\n",
        "            plt.plot(X_new, y_predict, style)\n",
        "\n",
        "        random_index = np.random.randint(m)\n",
        "        xi = X_b[random_index : random_index + 1]\n",
        "        yi = y[random_index: random_index + 1]\n",
        "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
        "        eta = learning_schedule(epoch * m + i)\n",
        "        theta = theta - eta * gradients\n",
        "        theta_path_sgd.append(theta)\n",
        "        \n",
        "plt.plot(X, y, 'b.')\n",
        "plt.xlabel('$x_1$', fontsize = 18)\n",
        "plt.ylabel('$y$', rotation = 0, fontsize = 18)\n",
        "plt.axis([0, 2, 0, 15])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMR_JXYDn9Ku"
      },
      "source": [
        "# Code4.10\n",
        "# 使用sklearn中的SGDRegressor\n",
        "\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "sgd_reg = SGDRegressor(max_iter = 1000, tol = 1e-3, penalty = None, eta0 = 0.1)\n",
        "sgd_reg.fit(X, y.ravel())\n",
        "\n",
        "print(sgd_reg.intercept_)\n",
        "print(sgd_reg.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bgz97lSevcQ"
      },
      "source": [
        "# Code4.(10.5)\n",
        "# 小批量梯度下降(2021-01-17)\n",
        "\n",
        "theta_path_mgd = []\n",
        "\n",
        "n_iterations = 50\n",
        "minibatch_size = 20\n",
        "\n",
        "np.random.seed(42)\n",
        "theta = np.random.randn(2, 1)\n",
        "\n",
        "t0, t1 = 200, 1000\n",
        "def learning_schedule(t):\n",
        "    return t0 / (t + t1)\n",
        "\n",
        "t = 0\n",
        "for epoch in range(n_iterations):\n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_b_shuffled = X_b[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "    for i in range(0, m, minibatch_size):\n",
        "        t += 1\n",
        "        xi = X_b_shuffled[i: i + minibatch_size]\n",
        "        yi = y_shuffled[i: i + minibatch_size]\n",
        "        gradients = 2 / minibatch_size * xi.T.dot(xi.dot(theta) - yi)\n",
        "        eta = learning_schedule(t)\n",
        "        theta = theta - eta * gradients\n",
        "        theta_path_mgd.append(theta)\n",
        "\n",
        "print(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etjDwcwkn9Ku"
      },
      "source": [
        "# Code4.11\n",
        "# 为多项式回归生成数据集\n",
        "\n",
        "m = 100\n",
        "X = 6 * np.random.rand(m, 1) - 3\n",
        "y = 0.5 * X ** 2 + np.random.randn(m, 1)\n",
        "\n",
        "plt.scatter(X, y)\n",
        "plt.axis([-3, 3, -5, 10])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CM7c8X2n9Ku"
      },
      "source": [
        "# Code4.12\n",
        "# 使用多项式回归来拟合\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly_features = PolynomialFeatures(degree = 2, include_bias = False)\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "\n",
        "print(X[0])\n",
        "print(X_poly[0])\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_poly, y)\n",
        "\n",
        "print(lin_reg.intercept_)\n",
        "print(lin_reg.coef_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lVsLK7on9Kv"
      },
      "source": [
        "# Code4.13\n",
        "# 绘制学习曲线，欠拟合\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def plot_learning_curves(model, X, y):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)\n",
        "    train_errors = []\n",
        "    val_errors = []\n",
        "    for m in range(1, len(X_train)):\n",
        "        model.fit(X_train[: m], y_train[: m])\n",
        "        y_train_predict = model.predict(X_train[: m])\n",
        "        y_val_predict = model.predict(X_val)\n",
        "        train_errors.append(mean_squared_error(y_train[: m ], y_train_predict))\n",
        "        val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
        "    plt.plot(np.sqrt(train_errors), 'r-+', linewidth = 2, label = 'train')\n",
        "    plt.plot(np.sqrt(val_errors), 'b-', linewidth = 3, label = 'val')\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "plot_learning_curves(lin_reg, X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAumaIKan9Kv"
      },
      "source": [
        "# Code4.14\n",
        "# 模拟过拟合\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "polynomial_regression = Pipeline([\n",
        "    ('poly_features', PolynomialFeatures(degree = 10, include_bias = False)),\n",
        "    ('lin_reg', LinearRegression())\n",
        "])\n",
        "\n",
        "plot_learning_curves(polynomial_regression, X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrKiOHYkn9Kv"
      },
      "source": [
        "# Code4.15\n",
        "# 岭回归\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge_reg = Ridge(alpha = 1, solver = 'cholesky')\n",
        "ridge_reg.fit(X, y)\n",
        "print(ridge_reg.predict([[1.5]]))\n",
        "\n",
        "sgd_reg = SGDRegressor(penalty = 'l2')\n",
        "sgd_reg.fit(X, y.ravel())\n",
        "print(sgd_reg.predict([[1.5]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgZ-LtGNn9Kw"
      },
      "source": [
        "# Code4.16\n",
        "# Lasso\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso_reg = Lasso(alpha = 0.1)\n",
        "# 也可以使用这个\n",
        "# lasso_reg = SGDRegressor(penalty = 'l1')\n",
        "\n",
        "lasso_reg.fit(X, y)\n",
        "print(lasso_reg.predict([[1.5]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw_z_ehyn9Kw"
      },
      "source": [
        "# Code4.17\n",
        "# 弹性网络\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "elastic_net = ElasticNet(alpha = 0.1, l1_ratio = 0.5)\n",
        "elastic_net.fit(X, y)\n",
        "print(elastic_net.predict([[1.5]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iwGtVGvn9Kw"
      },
      "source": [
        "# Code4.18\n",
        "# 2021-01-17 修改\n",
        "# 提前停止法的基本实现\n",
        "\n",
        "# 准备数据\n",
        "np.random.seed(42)\n",
        "m = 100\n",
        "X = 6 * np.random.rand(m, 1) - 3\n",
        "y = 2 + X + 0.5 * X**2 + np.random.randn(m, 1)\n",
        "\n",
        "# 数据预处理\n",
        "X_train, X_val, y_train, y_val = train_test_split(X[:50], y[:50].ravel(), test_size = 0.5, random_state = 10)\n",
        "\n",
        "poly_scaler = Pipeline([\n",
        "    ('poly_features', PolynomialFeatures(degree = 90, include_bias = False)),\n",
        "    ('std_scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "X_train_poly_scaled = poly_scaler.fit_transform(X_train)\n",
        "X_val_poly_scaled = poly_scaler.transform(X_val)\n",
        "\n",
        "# 训练与选择模型\n",
        "from copy import deepcopy\n",
        "\n",
        "sgd_reg = SGDRegressor(max_iter = 1, tol = -np.infty, warm_start = True, penalty = None, learning_rate = 'constant', eta0 = 0.0005, random_state = 42)\n",
        "\n",
        "minimum_val_error = float('inf')\n",
        "best_epoch = None\n",
        "best_model = None\n",
        "\n",
        "for epoch in range(1000):\n",
        "    sgd_reg.fit(X_train_poly_scaled, y_train)\n",
        "    y_val_predict = sgd_reg.predict(X_val_poly_scaled)\n",
        "    val_error = mean_squared_error(y_val, y_val_predict)\n",
        "    if val_error < minimum_val_error:\n",
        "        minimum_val_error = val_error\n",
        "        best_epoch = epoch\n",
        "        best_model = deepcopy(sgd_reg)\n",
        "\n",
        "print(best_epoch)\n",
        "print(best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPZh3bgNn9Kx"
      },
      "source": [
        "# Code4.19\n",
        "# 加载数据集\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "print(iris.DESCR)\n",
        "\n",
        "X = iris['data'][:, 3:]\n",
        "y = (iris['target'] == 2).astype(np.int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NyoL-bhn9Kx"
      },
      "source": [
        "# Code4.20\n",
        "# 逻辑回归训练\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmuUTSZXn9Kx"
      },
      "source": [
        "# Code4.21\n",
        "# 修改于2021-01-17\n",
        "# 逻辑回归测试\n",
        "\n",
        "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
        "y_proba = log_reg.predict_proba(X_new)\n",
        "decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\n",
        "\n",
        "plt.figure(figsize = (8, 3))\n",
        "plt.plot(X[y == 0], y[y == 0], 'bs')\n",
        "plt.plot(X[y == 1], y[y == 1], 'g^')\n",
        "plt.plot([decision_boundary, decision_boundary], [-1, 2], 'k:', linewidth = 2)\n",
        "plt.plot(X_new, y_proba[:, 1], 'g-', linewidth = 2, label = 'Iris virginica')\n",
        "plt.plot(X_new, y_proba[:, 0], 'b--', linewidth = 2, label = 'Not Iris virginica')\n",
        "plt.text(decision_boundary + 0.02, 0.15, 'Decision boundary', fontsize = 14, color = 'k', ha = 'center')\n",
        "plt.arrow(decision_boundary, 0.08, -0.3, 0, head_width = 0.05, head_length = 0.1, fc = 'b', ec = 'b')\n",
        "plt.arrow(decision_boundary, 0.92, 0.3, 0, head_width = 0.05, head_length = 0.1, fc = 'g', ec = 'g')\n",
        "plt.xlabel('Petal width (cm)', fontsize = 14)\n",
        "plt.ylabel('Probability', fontsize = 14)\n",
        "plt.legend(loc = 'center left', fontsize = 14)\n",
        "plt.axis([0, 3, -0.02, 1.02])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrDzrk2Pn9Kx"
      },
      "source": [
        "# Code4.22\n",
        "# Softmax回归\n",
        "\n",
        "X = iris['data'][:, (2, 3)]\n",
        "y = iris['target']\n",
        "\n",
        "softmax_reg = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', C = 10)\n",
        "softmax_reg.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXAxAXW6n9Ky"
      },
      "source": [
        "# Code4.23\n",
        "# Softmax测试\n",
        "\n",
        "print(softmax_reg.predict([[5,2]]))\n",
        "print(softmax_reg.predict_proba([[5, 2]]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}