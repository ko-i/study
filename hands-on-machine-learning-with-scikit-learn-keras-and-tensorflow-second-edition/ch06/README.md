# 第6章 决策树

---

### 练习题
---

###### 1. 如果训练集有100万个实例，训练决策树（无约束）大致深度是多少？
> log(1000000)
---
###### 2. 通常来说，子节点的基尼不纯度是高于还是低于其父节点？是通常更高还是更低？还是永远更高，还是更低？ 
> 通常来说是比父节点低的，除非子节点之间的基尼不纯度相差太大。
---
###### 3. 如果决策树过拟合训练集，减少max_depth是否是一个好主意？
> 是。
---
###### 4.如果决策树对训练集欠拟合，尝试缩放特征是否为一个好主意？ 
> 不是。
---
###### 5. 如果在包含100万个实例的训练集上训练决策树需要一个小时，那么在包含1000万个实例的决策树上训练决策树，大概需要多长时间？ 
> 11.7小时。
---
###### 6. 如果训练集包含10万个实例，设置presort = True可以加快训练吗？ 
>  只有实例数量较少（1000个）时，这个方法才能加快训练。
---
###### 7. 8. 
> 未完成
---