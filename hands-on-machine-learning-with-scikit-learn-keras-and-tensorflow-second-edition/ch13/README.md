# 第13章 使用TensorFlow加载和预处理数据

---

### 练习题
---

###### 1. 为什么要使用Data API？
> 获取大数据集并对其进行有效地预处理可能是一个复杂的工程挑战。数据API简化了这个该过程，他提供了许多功能，包括从各种来源加载数据，从多个来源并行读取数据，对其进行转换，对记录进行交织，打乱数据的次序，批处理和预取。
---
###### 2. 将大数据集拆分成多个文件有什么好处？
> 可以在使用乱序缓冲区将其次序打乱为更细的即便之前，先对其进行粗略的乱序。他还使处理单个计算机上无法容纳的庞大数据集成为可能。操作成千上万个小文件比操作一个大文件更容易。
---
###### 3. 在训练过程中，如何分辨输入流水线是瓶颈？你可以如何解决？
> 可以查看GPU有没有被完全利用。可以换用更大更多的cpu和ram的计算机。
---
###### 4. 你可以将任何二进制文件保存在TFRecord文件，还是仅保存序列化的协议缓冲区？
> 最好还是保存序列化的协议缓冲区，因为这样可以方便的在其它代码中使用。
---
###### 5. 为什么要将所有数据转换为Example protobuf格式？为什么不使用自己的protobuf定义？
> 因为TensorFlow对其有一些列的操作支持。
---
###### 6. 使用TFRecords时，应何时激活压缩？为什么不系统的进行呢？
> 在需要进行网络传输数据的时候。
---
###### 7. 对数据进行预处理，可以再编写数据文件时，或者在tf.data流水线内，或者在模型内预处理层中，或使用TF Transform。你能否列举出每种方法的一些利弊？
>  略
---
###### 8. 列举出一些可用于编码分类特征的常用技术。文本呢？
> 略
---