# 第19章 大规模训练和部署TensorFlow模型

---

### 练习题
---

###### 1. SavedModel包含什么？如何检查其内容？
> SavedModel包含一个TensorFlow模型，包括其架构（计算图）和权重。他保存在一个目录中，该目录包含一个save_model.pb文件和一个variables子目录--该文件定义了计算图，该子目录包含变量值。对于包含大量权重的模型，可以将这些变量值拆分为多个文件。SavedModel还包括assets子目录，该子目录可能包含其他数据，例如词汇表文件，类名或该模型的某些实例。准确的说，SavedModel可以包含一个或多个元图。元图是一个计算图，外加一些函数签名定义。每个元数据有一组标签来标识。要查看SavedModel，你可以使用命令行工具save_model_cli或使用tf.saved_model.load()来加载它并在python中查看。
---
###### 2. 何时应使用TF Serving？它的主要特点是什么？可以使用哪些工具来进行部署？
> TF Serving允许你部署多个TensorFlow模型，使其可以通过RESTAPI或gRPCAPI轻松地被所有应用程序访问。直接在你的应用程序中使用模型会使在所有应用程序中部署模型的新版本变得更加困难。实现你自己的微服务来包装TF模型需要额外的工作，并且很难匹配TF Serving的特性。TF Serving具有许多特性，他可以监视目录并自动部署放置在其中的模型，并且你不必更改甚至重新启动任何应用程序就可以从新的模型版本中受益。他的速度很快、很好测试并且扩展性非常好。它支持对实验模型进行A/B测试，并仅向部分用户部署新的模型版本。TF Serving还能够将单个请求分组，可以使他在GPU上一起运行。要部署TF Serving，你可以从源代码安装它，但是使用Docker映像安装要简单得多。要部署TF Serving Docker集群，你可以使用编排工具也可以是用哪个完全托管的解决方案。
---
###### 3. 如何跨多个TF Serving实例部署一个模型？
> 要夸多个TF Serving实例来部署模型，你需要做的就是配置这些TF Serving实例来监视相同的models目录，然后将新模型作为SavedModel导出到子目录中。
---
###### 4. 什么时候应该用gRPC API而不是REST API来查询一个被TF Serving服务的模型？
> gRPC API 比REST更有效。但是，他的客户端库不那么广泛，如果在使用REST时使用压缩，则你可以获得几乎相同的性能，因此，当你需要尽可能高的性能并且客户端不限于REST时，可以使用RPC。
---
###### 5. TFLite减少模型大小以使其在移动端或嵌入式设备上运行的不同方式是什么？
> * 它提供了一个可以优化SavedModel的转换器：他可以缩小模型并减少延迟，为此，他修剪进行预测不需要的操作，并且可能的情况下优化和融合操作。
> * 转换器还可以执行训练后的量化：该技术极大地见笑了模型大小，因此下载和存储速度更快。
> * 他使用FlatBuffer格式来保存优化的模型，该格式可以直接加载到RAM中，而无需进行介系。这样可以减少加载时间和占用的内存。
---
###### 6. 什么是量化意识训练，为什么你需要它？
> 有量化意识的训练包括在训练过程中想模型添加伪造的量化操作。这使模型能够学会忽略量化噪声。最终的权重会对量化更加稳健。
---
###### 7. 什么事模型并行和数据并行，为什么通常建议使用后者？
> 模型并行意味着将模型分成多个部分，在多个设备上并行运行它们，希望在训练和推理期间加快模型的运行速度。数据并行意味着创建模型的多个精确副本，并将其部署在多个设备上。在训练过程的每次迭代中，每个副本会获得不同批次的数据，并且它会根据模型参数来计算损失的梯度。在同步数据并行处理中，汇总所有副本的梯度，然后优化器执行梯度下降步骤。可以将参数集中，或者在所有副本之间复制参数，并使用AllReduce使其保持同步，异步数据并行处理中，参数是集中地，副本彼此独立运行，每个副本都在每次训练迭代结束时直接跟新中心参数，而不必等待其它副本。为了加快训练速度，通常来说，数据并行性要比模型并行性更好。这主要是因为他需要较少的跨设备通信。此外，它更容易实现，并且对任何模型都以相同的方式工作，而模型并行则需要分析模型来确定将其分成模块的最佳方法。
---
###### 8. 在多台服务器上训练模型时，可以使用什么分布式策略？如何选择使用哪一个？
> * MultiWorkerMirroredStrategy并行执行镜像的数据。该模型在所有可用的服务器和设备上复制，每个副本在每次训练迭代时获得不同批次的数据，并计算其自己的梯度。使用分布式AllReduce实现来计算并在所有副本之间共享梯度的平均值，所有副本都执行相同的梯度下降步骤。由于所有服务器和设备的处理方式都完全相同，因此该策略使用起来最简单，性能良好。通常，你应该使用此策略。它的主要局限是他要求模型适合每个副本中的RAM。
> * ParameterServerStrategy执行异步数据并行。该模型在所有工人上的所有设备复制，并且参数在所有参数服务器上分片。每个工人都有自己的训练循环，与其他工人异步进行。在每次训练迭代中，每个工人都会获取自己的数据批次，从参数服务器中获取模型参数的最新版本，然后针对这些参数计算损失的梯度，将其发送到参数服务器。最后，参数服务器使用这些梯度执行梯度下降算法。此策略通常比以前的策略满，而且部署起来有些困难，因为他需要管理参数服务器。但是，训练不适合GPU RAM的大型模型很有用。
---