# hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow-edition2
> 《机器学习实战 基于Scikit-Learn，Keras和TensorFlow（第二版）》Python3代码实现

---
Python版本：Python3.8.6

基本环境：numpy（1.19.1），pandas（1.1.3），matplotlib（3.3.1），sciket-learn（0.23.2），tensorflow（2.3.0）

看书中是用jupyter-notebook编辑代码，我这里就直接使用Anaconda3来自动装配环境了，以上大部分基本包都以默认安装，用最新版的就好。

---
本仓库目录结构非常简单，每一章的内容就放在`chxx`目录下，其中主要的有相关的jupter-notebook代码文件`chxx.ipynb`，有关章末编程作业（如果有）的代码我会视情况写在章节代码内或放在`hwxx.ipynb`中。我将每章更详细的说明（如果需要）与每章相关的习题完成一起放在每章目录下的`README.md`中，各章会用到的数据集集中放在了dataset中（但如果文件过大就不上传了，但会在代码中说明下载地址）。

代码文件说明：因为是自己再实现一遍，所以代码文件组织不会跟官方给出的一样，我会根据自己的习惯来组织与改写代码：比如遵循自己习惯的命名方式，增加某些测试相关代码（我也会尽量全都注释掉），省略一些我认为无关紧要的代码，甚至重写整个实现代码。有些模块、数据集加载较慢，我就会在jupyter-note中将其拆分，我也会适当的将属于一个完整例子的代码放在一起，暂时以前缀`CodeX.Y`来区分，`X`代表章节，`Y`表示章节内代码顺序。如有运行的需要，请`Run all`。

课后的编程作业就先搁置一段时间。

---

### 以下为日记

---
2020-10-21

新书到了，内心非常激动！很厚的一本书，应该会陪伴我很久。在这里记录我学习这本书的过程心得之类。

今天完成了第一章，第二章也写了一点，得益于有一些python基础与本书细致通俗的解释，还并没有遇到什么学习与阅读上的困难。

这是一本好书，相信在阅读完后会我对机器学习的应用更加得心应手。

希望自己有所成长。

---
2020-10-22

完成了第二章，了解到了将机器学习运用到生产过程中的整体过程，虽然仅是粗略的见识了一下关键过程，但我也对这整个处理流程的复杂性感到赞叹，尤其是各种探索数据，处理数据。

因为自己的相关知识能力还太过浅薄，无法顺利完成第二章相关作业，所以打算先放一放，等之后技能熟练了再来看看。

完成了第三章，除了了解了一些分类方法之外，主要学到了针对分类器性能的评估方法，还对在大数据集下KNN的速度之慢有了深刻的体验。

是疯狂压榨电脑性能的一天，我可怜的小破电脑哈哈哈哈。

连续两章的课后编程作业都给了我很大打击，我还有很多东西要学啊。

读了一点第四章的内容。

---
2020-10-23

完成了第四章的内容。对线性回归的标准方程，三个梯度下降算法的内在运算方法与实际scikit-learn中的使用都有了了解，还学会了运用逻辑回归算法的原理与实现方法。

完成了第五章的内容。但是对于支持向量的数学原理，涉及到的数学公式还不明白。但对于基本用法，支持场景与其强大的性能还是有了充分的了解。

完成了第六章的内容。这几张的代码量都不多，scikit-learn封装好的这些机器学习方法，让我们只要一两行代码就能搞定训练与预测，真的是太方便了。

完成了第七章的内容。了解了各种集成方法，代表性的随机森林，极端随机树，AdaBoost，梯度上升。集成方法很重要，它可以大大提升性能，也许会对我之后的研究各种分类器回归器的组合使用有所启发。

今天的内容涉及了一些数学内容，看起来还是很吃力的，但是大致思想都已了解，使用起来也没有问题。知道了梯度下降算法很重要，在之后的深度学习中也会有作用，支持向量机非常的强力，可以说是最有效的分类器也没问题，决策树相对来说会弱一些，但也有它适用的场景，但由决策树构成的随机森林，就又是另一个非常优秀的分类器了。

---
2020-10-24

今日休息。

---
2020-10-25

完成了第八章。

完成了第九章。终于要进入期待已久的深度学习了！

---
2020-10-26

完成了第十章，对keras神经网络训练的基本流程有了大致了解。

完成了第十一章，这一张了解了更多关于训练深度神经网络更细节的过程与内容，各种调试方法加速方法优化方法，看到后面脑袋都成浆糊了哈哈哈哈。但学到了满满的干货还是非常高兴的！

今天我竟然在图书馆坐了13个小时，明天再接再厉！

---
2020-10-27

完成了第十二章，这一章真真让我吐血，虽然看了一白天，但还是只了解了个皮毛。尤其是自定义循环这一块，我希望自己以后永远不要用到它。

感觉从今天开始读书的速度慢了下了，七八个小时今天只前进了35页，这样也好，日子还长不要着急，慢慢来尽量弄明白。

---
2020-10-28

完成了第十三章，在tensorflow_datasets这一块内容上耗了很久，不知道为啥自己的电脑一直下载数据集失败，最后只好在网上找到现成的数据集再模拟了tfds.load()下载目录的结构以后才成功绕过从google下载，原因貌似是我这个电脑的认证有问题，导致访问google的数据库被拒绝。

终于步入了最激动人心的卷积神经网络章节，可以开始疯狂压榨电脑性能了！

我又吐血了，满怀激动的写完训练模型，然后发现cpu训练的太慢，就准备捣鼓一下用GPU算，然后就走上了一条下载各种版本的cuda，cudnn，python，tensorflow的不归路。发生了一个能检测到gpu设备但是在导入张量运算时会崩溃，加载cudnn模块失败，折腾了老半天最后发现原来是tensorflow2.0版本在显存获取上有bug，要不就是我显存太小。总之最后加了一段限制缓存获取的代码就能成功运行了。白瞎了我从下午整到晚上，爷吐了！

---
2020-10-29

今天学完了第十四章，对卷积神经网络有了一些了解，能运用卷积神经网络处理一些问题，发现自己的难点在于获得数据与正确的数据格式。也发现了colab这个好用的平台，以后就可以把代码编辑的事情放在平台上了。

时间过得好快，不知不觉就到了晚饭时间，而我才看了二十几页，看来内容是越来越难。不知道到底学了些啥但也学到了一些。

---
2020-10-30

完成了第十五章，脑子又是一团浆糊，第一次接触CNN，RNN，虽说不用深入了解运行原理就可以使用，但这样还是不妥，意识到了机器学习之路，尤其是深度学习方面还任重道远。

第十六章也完成了一些，但训练了很久然后中途报错就很搞我心态，改了一晚上的代码，还没改完，身心俱疲，明天休息一天。

---
2020-10-31

今日休息。

说是休息，但昨天留下的bug意难平，稍微改完了十六章代码的bug，总算是都跑通了，还剩下一些文字阅读部分未完成，就留到明天吧。

---
2020-11-01

完成了第十六章，对自然语言处理的一些方法都有了初步的了解，也仅限初步，真的。

完成了第十七章，今天的效率好高呀，对自动编码器的基本知识也有了了解，自动编码器可以做很多有意思的事啊，比如网上的换脸之类。以后可以有空玩一玩。

明天就可以进入我最感兴趣的强化学习章节了，加油！

---
2020-11-02

完成了强化学习除了tf-agents之前的内容。具体的马尔科夫过程和Q学习算法还有些懵，但大概道理是明白了。tf-agents貌似在colab上运行环境有问题，鼓捣了半天还是在本地装好了环境，测试通过了，明天把剩下的部分完成。

今天又是效率奇高又收获颇丰的一天。明天继续加油！

---
2020-11-03

完成了强化学习章节，强化学习是一个很有趣但是也非常难的一个领域，虽说已经跟着代码完成了一遍，但TF-agents库和gym库现在也只是有个大致的了解，这一部分还有很多内容要学要补充。我要不要深入研究呢？

完成了最后一部分。

呼，长舒了一口气，过完了整本书，不容易也容易。现在回想看来我这一次其实阅读的并不算细致，可以说是十分粗糙，对其中很多概念也只涉及到了皮毛，尤其是在涉及到具体深奥的数学原理时，或一些新兴框架，比如tf-agents，其实也没有多大掌握。其中所涉及的代码重现其实也很简陋，对比作者实现的源代码来说还差的很多（但也能感受到自己的编码能力在进步），具体的编程作业也没有实现。

但也有很多的长进：
> 1. 了解了机器学习领域的整体框架，它都有什么内容，每个内容大致又是什么，了解到了很多经典的，新颖的优秀的算法。
> 2. 对Scikit-learn和TensorFlow库的基础运用十分熟悉了。
> 3. 对整个机器学习运用实践的流程有了清楚的认识。

对于接下来的打算，我准备
> 1. 阅读书中所提到的一些经典文献。
> 2. 看一些机器学习尤其是深度学习领域的相关视频，巩固与加其深数学原理的理解。
> 3. 可以尝试参加一些Kaggle比赛，将自己所学运用出来。
> 4. 这本书还是需要再次认真的阅读，仓库的代码也需要补充和完善。
> 5. 但最近，我体会到了一整天都泡在一种知识里的艰难，（每天看这本书看到晚上时脑袋都不好使了）所以我打算先学习一下C代码的基础，这样以后在白天学习学累了，晚上可以做一些算法题来换换脑袋。

感谢作者。

下个仓库见！