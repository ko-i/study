{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-10-25 created by Akson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.1\n",
    "# 使用sklearn的库来实现TLU网络\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.2\n",
    "# 初识tf和keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.3\n",
    "# 加载数据集\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(X_train_full.shape)\n",
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.4\n",
    "# 处理数据\n",
    "\n",
    "# 分出验证集，并且将数据缩放至0，1之间\n",
    "X_valid = X_train_full[: 5000] / 255.0\n",
    "X_train = X_train_full[5000: ] / 255.0\n",
    "y_valid = y_train_full[: 5000]\n",
    "y_train = y_train_full[5000: ]\n",
    "\n",
    "# 给每个类取名\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(class_names[y_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.5\n",
    "# 建立神经网络！\n",
    "\n",
    "# 建立一个最简单的顺序模型\n",
    "model = keras.models.Sequential()\n",
    "# 添加一个将图片变为一维数组的层\n",
    "model.add(keras.layers.Flatten(input_shape = [28, 28]))\n",
    "# 添加一个具有300个神经元的隐藏层\n",
    "model.add(keras.layers.Dense(300, activation = 'relu'))\n",
    "# 添加一个具有100个神经元的隐藏层\n",
    "model.add(keras.layers.Dense(100, activation = 'relu'))\n",
    "# 添加一个具有10各单元的输出层\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.6\n",
    "# 模型基本情况\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.7\n",
    "# 模型层情况\n",
    "\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.8\n",
    "# 有关模型层的一些操作\n",
    "\n",
    "hidden1 = model.layers[1]\n",
    "print(hidden1.name)\n",
    "\n",
    "print(model.get_layer(hidden1.name) is hidden1)\n",
    "\n",
    "weights, biases = hidden1.get_weights()\n",
    "print(weights)\n",
    "print(weights.shape)\n",
    "print(biases)\n",
    "print(biases.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.9\n",
    "# 编译模型，指定损失函数和要使用的优化器等\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.10\n",
    "# 开始训练！\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 30, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.11\n",
    "# 绘制训练曲线\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize = (8, 5))\n",
    "plt.grid = True\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.12\n",
    "# 在测试集中评估\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.13\n",
    "# 使用模型进行预测\n",
    "\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "print(y_proba)\n",
    "print(np.argmax(y_proba, axis = -1))\n",
    "print(np.array(class_names)[np.argmax(y_proba, axis = -1)])\n",
    "print(y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.14\n",
    "# 试试用神经网络做回归任务\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 引入加州房产数据集\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train).astype(np.int)\n",
    "X_valid = scaler.transform(X_valid).astype(np.int)\n",
    "X_test = scaler.transform(X_test).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.15\n",
    "# 构建网络模型\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu', input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)  # 一个神经元的输出层\n",
    "])\n",
    "\n",
    "# 编译训练\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'sgd')\n",
    "history = model.fit(X_train, y_train, epochs = 20, validation_data = (X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "print(y_test[:3])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.16\n",
    "# wide-deep model\n",
    "\n",
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs = [input_], outputs = [output])\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'sgd')\n",
    "history = model.fit(X_train, y_train, epochs = 20, validation_data = (X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "print(y_test[:3])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.17\n",
    "# wide-deep model(input split subset)\n",
    "\n",
    "inputA = keras.layers.Input(shape = [5], name = 'wide_input')\n",
    "inputB = keras.layers.Input(shape = [6], name = 'deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(inputB)\n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "concat = keras.layers.concatenate([inputA, hidden2])\n",
    "output = keras.layers.Dense(1, name = 'output')(concat)\n",
    "model = keras.Model(inputs = [inputA, inputB], outputs = [output])\n",
    "model.compile(loss = 'mse', optimizer = keras.optimizers.SGD(lr = 1e-3))\n",
    "\n",
    "# 整理输入数据格式\n",
    "X_train_A = X_train[:, :5]\n",
    "X_train_B = X_train[:, 2:]\n",
    "X_valid_A = X_valid[:, :5]\n",
    "X_valid_B = X_valid[:, 2:]\n",
    "X_test_A = X_test[:, :5]\n",
    "X_test_B = X_test[:, 2:]\n",
    "X_new_A = X_test_A[:3]\n",
    "X_new_B = X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs = 20, validation_data = ((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))\n",
    "\n",
    "print(y_test[:3])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.18\n",
    "# Aux output\n",
    "\n",
    "inputA = keras.layers.Input(shape = [5], name = 'wide_input')\n",
    "inputB = keras.layers.Input(shape = [6], name = 'deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(inputB)\n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "concat = keras.layers.concatenate([inputA, hidden2])\n",
    "aux_output = keras.layers.Dense(1, name = 'aux_output')(hidden2)\n",
    "output = keras.layers.Dense(1, name = 'output')(concat)\n",
    "model = keras.Model(inputs = [inputA, inputB], outputs = [output, aux_output])\n",
    "model.compile(loss = ['mse', 'mse'], loss_weights = [0.9, 0.1], optimizer = keras.optimizers.SGD())\n",
    "\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs = 20, validation_data = ([X_valid_A, X_valid_B], [y_valid, y_valid]))\n",
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.19\n",
    "# sub-class\n",
    "\n",
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units = 30, activation = 'relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation = activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation = activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([intput_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        \n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.20\n",
    "# Save and load model\n",
    "inputA = keras.layers.Input(shape = [5], name = 'wide_input')\n",
    "inputB = keras.layers.Input(shape = [6], name = 'deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(inputB)\n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "concat = keras.layers.concatenate([inputA, hidden2])\n",
    "aux_output = keras.layers.Dense(1, name = 'aux_output')(hidden2)\n",
    "output = keras.layers.Dense(1, name = 'output')(concat)\n",
    "model = keras.Model(inputs = [inputA, inputB], outputs = [output, aux_output])\n",
    "model.compile(loss = ['mse', 'mse'], loss_weights = [0.9, 0.1], optimizer = keras.optimizers.SGD())\n",
    "model.fit([X_train_A, X_train_B], [y_train, y_train], epochs = 20, validation_data = ([X_valid_A, X_valid_B], [y_valid, y_valid]))\n",
    "\n",
    "print(model.summary())\n",
    "model.save('housing_model.h5')\n",
    "model = keras.models.load_model('housing_model.h5')\n",
    "print(model.summary())\n",
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.21\n",
    "# call_back\n",
    "\n",
    "# my_call_back\n",
    "class PrintValTrainRatioCallBack(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print('\\nval / train: {:.2f}'.format(logs['val_loss'] / logs['loss']))\n",
    "\n",
    "inputA = keras.layers.Input(shape = [5], name = 'wide_input')\n",
    "inputB = keras.layers.Input(shape = [6], name = 'deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(inputB)\n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "concat = keras.layers.concatenate([inputA, hidden2])\n",
    "aux_output = keras.layers.Dense(1, name = 'aux_output')(hidden2)\n",
    "output = keras.layers.Dense(1, name = 'output')(concat)\n",
    "model = keras.Model(inputs = [inputA, inputB], outputs = [output, aux_output])\n",
    "model.compile(loss = ['mse', 'mse'], loss_weights = [0.9, 0.1], optimizer = keras.optimizers.SGD())\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('housing_model_checkpoint.h5', save_best_only = True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n",
    "# my callback\n",
    "print_val_train_ratio_cb = PrintValTrainRatioCallBack()\n",
    "\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs = 20, callbacks = [print_val_train_ratio_cb, checkpoint_cb, early_stopping_cb], validation_data = ([X_valid_A, X_valid_B], [y_valid, y_valid]))\n",
    "\n",
    "model = keras.models.load_model('housing_model_checkpoint.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.22\n",
    "# TensorBoard\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "print(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.23\n",
    "# TensorBoard callback\n",
    "\n",
    "inputA = keras.layers.Input(shape = [5], name = 'wide_input')\n",
    "inputB = keras.layers.Input(shape = [6], name = 'deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation = 'relu')(inputB)\n",
    "hidden2 = keras.layers.Dense(30, activation = 'relu')(hidden1)\n",
    "concat = keras.layers.concatenate([inputA, hidden2])\n",
    "aux_output = keras.layers.Dense(1, name = 'aux_output')(hidden2)\n",
    "output = keras.layers.Dense(1, name = 'output')(concat)\n",
    "model = keras.Model(inputs = [inputA, inputB], outputs = [output, aux_output])\n",
    "model.compile(loss = ['mse', 'mse'], loss_weights = [0.9, 0.1], optimizer = keras.optimizers.SGD())\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs = 20, callbacks = [tensorboard_cb], validation_data = ([X_valid_A, X_valid_B], [y_valid, y_valid]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.24\n",
    "# start tensorboard\n",
    "\n",
    "# 这个在jupyter中找不到tensorboard命令，我就直接在python终端环境中运行了\n",
    "# 记得先进到项目根目录中\n",
    "# 再输入\n",
    "# tensorboard --logdir=./my_logs --port=6006\n",
    "# 即可\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.25\n",
    "# play tensorboard\n",
    "\n",
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar('my_scalar', np.sin(step / 10), step = step)\n",
    "        data = (np.random.randn(100) + 2)\n",
    "        tf.summary.histogram('my_hist', data, buckets = 50, step = step)\n",
    "        images = np.random.rand(2, 32, 32, 3)\n",
    "        tf.summary.image('my_images', images * step / 1000, step = step)\n",
    "        texts = ['This step is ' + str(step), 'Its square is ' + str(step ** 2)]\n",
    "        tf.summary.text('my_text', texts, step = step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio('my_audio', audio, sample_rate = 48000, step = step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code10.26\n",
    "# 封装成sklearn的对象并用网格搜索最优超参数\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def build_model(n_hidden = 1, n_neurons = 30, learning_rate = 3e-3, input_shape = [8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape = input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr = learning_rate)\n",
    "    model.compile(loss = 'mse', optimizer = optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "param_distribs = {\n",
    "    'n_hidden': [0, 1, 2, 3],\n",
    "    'n_neurons': range(1, 100),\n",
    "    'learning_rate': [3e-4, 3e-3, 3e-2],\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter = 10, cv = 3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs = 100, validation_data = (X_valid, y_valid), callbacks = [keras.callbacks.EarlyStopping(patience = 10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
