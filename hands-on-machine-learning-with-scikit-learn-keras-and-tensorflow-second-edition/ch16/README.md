# 第16章 使用RNN和注意力机制进行自然语言处理

---

### 练习题
---

###### 1. 使用有状态RNN和无状态RNN有什么优缺点？
> 无状态RNN只能识别长度较小或等于在其训练的RNN的窗口大小的模式。相反，有状态RNN可以识别长期模式。但是，实现有状态RNN很困难，尤其是要正确准备数据集。而且有状态RNN并非总是能更好的工作，部分原因是连续的批量数据不是独立且不均匀分布（IID）。梯度下降不适合非IID数据。
---
###### 2. 人们为什么使用编码解码RNN而不是简单序列对序列的RNN进行自动翻译？
> 通常，如果逐词翻译一个句子，结果将很糟糕。最好是先阅读整个句子再翻译。普通序列到序列RNN在读取第一个单词后立即开始翻译句子，而编码器-解码器RNN将首先读取整个句子然后进行翻译。
---
###### 3. 如何处理可变长度的输入序列？可变长度的输出序列呢？
> 可变长度的输入序列可以通过填充较短的序列来处理，使一批量中的所有序列具有相同的长度，及使用掩码来确保RNN忽略填充令牌。为了获得更好的性能，你可能还想创建包含相似大小序列的批量。大小不一的张量可以容纳可变长度的序列，而tf.keras可能最终会支持他们，这将大大简化对可变长度输入序列的处理。对于可变长度的输出序列，如果预先知道输出序列的长度，则只需配置损失函数，这样就可以在序列末尾忽略令牌。类似的，使用模型的代码应用在序列结束之后忽略令牌。但是通常提前不知道输出序列的长度，因此解决方案是训练模型，以使其在每个序列的末尾输出序列结束令牌。
---
###### 4. 什么是集束搜索，为什么要使用它？你可以使用什么工具来实现它？
> 集束搜索是一种用于提高训练的编码器-解码器模型的性能的技术，例如在神经机器翻译中。该算法会跟踪k个最有前途的输出情感的简短列表，并在每个解码器步骤中尝试扩展一个单词。然后他只保留k个最有可能的句子。参数k成为集数宽度：它越大，将使用的cpu和RAM越多，单系统也越精确。与其在每个步骤上都贪婪地选择最可能的下一个单词来扩展橘子，该技术允许系统同时探索几个有希望的橘子。而且，这种技术手段很适合并行化。你可以使用Tensorflow插件轻松实现集束搜索。
---
###### 5. 什么是注意力机制？他有什么帮助？
> 注意力机制是最初在编码器-解码器模块中使用的一种技术，它使解码器可以更直接地访问输入序列，从而使其能够处理更长的输入序列。在每个解码器时间步长，当前的解码器状态和编码器的全部输出由对齐模型处理，该对齐模型输出每个输入时间步长的对齐分数。改分数指示输入的哪一部分与挡墙解码器时间步长最相关。然后，将编码器输出的加权中和输入到解码器，该解码器将生成下一个解码器状态和该时间步长的输出。使用注意力机制的主要好处是，编码器-解码器模型可以成功处理更长的输入序列。另一个好处是，对齐分数使模型更易于调试和解释：例如如果模型出错，则可以查看它关注的输入部分，这可以帮助诊断问题
---
###### 6. Transformer架构中最重要的层是什么？目的是什么？
> Transformer架构中最重要的层是Mutil-head Attention层（原始Transformer架构包含18个层，其中包括6个masked mha层）。他是语言模型的核心。其目的是使模型能够识别出哪些单词彼此最对齐，然后使用这些上下文线索来改善每个单词的表示。
---
###### 7. 你何时需要使用采样softmax？
> 当有很多类时，在训练分类模型时会使用采样的softmax。它基于模型为正确类别预测的对数和不正确单词样本的预测对数，计算交叉熵损失的近似值。相较于计算所有logit的softmax，然后估计交叉熵损失，这大大提高了训练速度。训练后可以正常使用模型，使用常规softmax函数根据所有逻辑计算所有类别概率。
---